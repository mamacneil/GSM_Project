{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model data for shark and ray meat landings and trade applied to 2012-2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Model for shark and ray meat landings and trade applied to 2014-2019 data\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pyt\n",
    "import rdata as rd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import scipy as sp\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Set figure style.\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "bd = os.getcwd() + \"/../Data/\"\n",
    "\n",
    "# Helper functions\n",
    "def indexall(L):\n",
    "    poo = []\n",
    "    for p in L:\n",
    "        if not p in poo:\n",
    "            poo.append(p)\n",
    "    Ix = np.array([poo.index(p) for p in L])\n",
    "    return poo, Ix\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "match = lambda a, b: np.array([b.index(x) if x in b else None for x in a])\n",
    "\n",
    "\n",
    "def unique(series: pd.Series):\n",
    "    \"Helper function to sort and isolate unique values of a Pandas Series\"\n",
    "    return series.sort_values().unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load landings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[83]:\n",
    "\n",
    "#'''\n",
    "#dnam = bd + \"/fishorshark/modeldatsharksraysImportNeg1augmented\"\n",
    "dnam = bd + \"modeldat_Augmented20250116_CHNupdates\"\n",
    "parsed = rd.parser.parse_file(dnam + \".RData\")\n",
    "converted = rd.conversion.convert(parsed)\n",
    "tmp = converted[\"modeldat\"]\n",
    "#'''\n",
    "#'''\n",
    "# Matrices\n",
    "speciesCountryIDMap = (\n",
    "    tmp[\"speciesCountryIDMap\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"country\", \"dim_2\": \"taxon\"})\n",
    "    .transpose(\"country\", \"species\", \"taxon\")\n",
    "    .sortby(\"country\")\n",
    ")\n",
    "\n",
    "logProbPrior = (\n",
    "    tmp[\"logProbPrior\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"country\", \"dim_2\": \"taxon\"})\n",
    "    .transpose(\"country\", \"species\", \"taxon\")\n",
    "    .sortby(\"country\")\n",
    ")\n",
    "\n",
    "priorImportance = (\n",
    "    tmp[\"priorImportance\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"country\"})\n",
    "    .transpose(\"country\", \"species\")\n",
    "    .sortby(\"country\")\n",
    ")\n",
    "\n",
    "OutputSpeciesCountryMapFull = (\n",
    "    tmp[\"OutputSpeciesCountryMapFull\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"country\"})\n",
    "    .transpose(\"country\", \"species\")\n",
    "    .sortby(\"country\")\n",
    ")\n",
    "\n",
    "OutputSpeciesCountryMap = (\n",
    "    tmp[\"OutputSpeciesCountryMap\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"country\"})\n",
    "    .transpose(\"country\", \"species\")\n",
    "    .sortby(\"country\")\n",
    ")\n",
    "\n",
    "SpeciesCommodityMap = (\n",
    "    tmp[\"speciesCommodities\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"commodity\"})\n",
    "    .sortby(\"species\")\n",
    ")\n",
    "\n",
    "# Grab key for shark/ray\n",
    "srkey = pd.read_csv(bd + \"taxonomy_20240205.csv\")\n",
    "srkey['group'] = srkey.Superorder.replace('Batoidea','rays').replace('Selachimorpha','sharks').to_numpy()\n",
    "\n",
    "# Trade covariate\n",
    "tradeImportance = (\n",
    "    tmp[\"tradeImportance\"]\n",
    "    .rename({\"dim_0\": \"species\", \"dim_1\": \"country\"})\n",
    "    .transpose(\"country\", \"species\")\n",
    "    .sortby(\"country\")\n",
    ")\n",
    "\n",
    "# Observed landings\n",
    "ObsLandings_ = pd.melt(tmp[\"national_landings_info\"], id_vars='country', value_name='landings')\n",
    "ObsLandings_.columns = ['country','species','obs_landings']\n",
    "ObsLandings_.species = np.array([s.replace('.' , ' ') for s in ObsLandings_.species.values])\n",
    "ObsLandings_ = ObsLandings_.set_index(['country','species']).to_xarray().to_dataarray()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified index and columns\n",
    "scorez = list(np.unique(priorImportance).astype(int).astype(str))\n",
    "tradeweightcounts = pd.DataFrame(index=priorImportance.country, columns=scorez).fillna(0)\n",
    "for c in priorImportance.country.to_numpy():\n",
    "    colz, valz = np.unique(priorImportance[priorImportance.country==c,:],return_counts=True)\n",
    "    tradeweightcounts.loc[c,colz.astype(int).astype(str)] = valz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeweightcounts_init = tradeweightcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tradeweightcounts_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorImportance.loc[:,priorImportance.species=='Fontitrygon garouaensis'] = -999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure available taxon matches for reported species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize species to taxon mapping\n",
    "SpeciesTaxonMAP = speciesCountryIDMap[0].drop_vars('country')\n",
    "#np.unique(SpeciesTaxonMAP, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match taxa to species level regardless of taxonomic level of aggregation\n",
    "for t in speciesCountryIDMap.taxon.values:\n",
    "    # Iterate over possible species for each taxon\n",
    "    for s in srkey[srkey.isin([t]).any(axis=1)]['species_binomial'].values:\n",
    "        try:\n",
    "            SpeciesTaxonMAP.loc[dict(species=s,taxon=t)] = 1\n",
    "        except:\n",
    "            pass\n",
    "#np.unique(SpeciesTaxonMAP, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species cutoff\n",
    "sppcutoff = -1\n",
    "# List of rarely caught species \n",
    "drop_spp = priorImportance.species.to_numpy()[priorImportance.max([\"country\"])<sppcutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of species remaining with prior importance less than or equal to cutoff removed\n",
    "#priorImportance.species.shape[0]-drop_spp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make temporary list of all taxon IDs\n",
    "tmp_taxon_ = speciesCountryIDMap.taxon.to_numpy()\n",
    "# Index taxons relative to what gets landed\n",
    "tmp_TaxonIDx = match(tmp[\"LandingsID\"], list(tmp_taxon_))\n",
    "# Temporary list of all species IDs\n",
    "tmp_species_ = speciesCountryIDMap.species.to_numpy()\n",
    "# Boolean of taxons that are to species level in observed landings\n",
    "tmp_tindx = pd.Series(tmp_taxon_[tmp_TaxonIDx]).str.count(\" \").to_numpy() == 0\n",
    "# Index of species in taxon that are observed as catches\n",
    "tmp_species_spp_id = match(tmp_taxon_[tmp_TaxonIDx[tmp_tindx == 0]], list(tmp_species_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique names of species in taxon list that are observed as taxon catches but have prior importance below cutoff\n",
    "tmp_spp = np.unique(tmp_species_[tmp_species_spp_id[np.log1p(tmp[\"allCatch\"])[tmp_tindx == 0]<sppcutoff]])\n",
    "#len(tmp_spp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species in drop list that are actually observed as in taxon+species (taxon) list\n",
    "tmp_spp = list(drop_spp[np.array([x in tmp_spp for x in drop_spp])])\n",
    "#len(tmp_spp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(priorImportance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab landings data to see which taxons have catch\n",
    "tmp_landings = tmp[\"allCatch\"]\n",
    "tmp_taxon = tmp[\"LandingsID\"]\n",
    "tmp_country = tmp[\"country\"]\n",
    "# Iterate over landings to ensure species are avaiable for taxon in country\n",
    "for l,t,c in zip(tmp_landings,tmp_taxon,tmp_country):\n",
    "    # Look for species landed with impossible priors\n",
    "    try:\n",
    "        if (priorImportance.sel(country=c,species=t)==-999)*(l>0):\n",
    "            priorImportance.loc[dict(country=c,species=t)] = sppcutoff\n",
    "            tmp_spp += [t]\n",
    "            #print(\"Changed \"+c+\" \"+t+' to '+str(sppcutoff) )\n",
    "    # Look for taxon landed with no possible species \n",
    "    except:\n",
    "        # Possible species for taxon\n",
    "        tax_spp = (SpeciesTaxonMAP.sel(taxon=t).species[SpeciesTaxonMAP.sel(taxon=t)==1]).values\n",
    "        # If all species are impossible for taxon\n",
    "        if (priorImportance.sel(country=c,species=tax_spp).mean()==-999.)*(l>0):\n",
    "            # Assign to possible species in nation\n",
    "            if OutputSpeciesCountryMapFull.sel(country=c,species=tax_spp).sum()>0:\n",
    "                axx = tax_spp[OutputSpeciesCountryMapFull.sel(country=c,species=tax_spp).to_numpy()>0]\n",
    "                xflax = 'ok'\n",
    "            else:\n",
    "                # Assign to most likely spp given global max\n",
    "                axx = tax_spp[(priorImportance.sel(species=tax_spp).max('country')==priorImportance.sel(species=tax_spp).max())]\n",
    "                xflax = 'not present'\n",
    "            # Change landings prior to cutoff value\n",
    "            priorImportance.loc[dict(country=c,species=axx)] = sppcutoff\n",
    "            tmp_spp += list(axx)\n",
    "            #print(\"Impossible \"+t+\" changed \"+c+\", spp are \"+xflax)\n",
    "            #print(axx)\n",
    "        \n",
    "        # If all species for taxon are below data-reduction cutoff\n",
    "        elif (priorImportance.sel(country=c,species=tax_spp).max()<sppcutoff)*(l>0):\n",
    "            # Assign to possible species in nation\n",
    "            if OutputSpeciesCountryMapFull.sel(country=c,species=tax_spp).sum()>0:\n",
    "                axx = tax_spp[OutputSpeciesCountryMapFull.sel(country=c,species=tax_spp).to_numpy()>0]\n",
    "                xflax = 'ok'\n",
    "            else:\n",
    "                # Assign to most likely spp given global max\n",
    "                axx = tax_spp[(priorImportance.sel(species=tax_spp).max('country')==priorImportance.sel(species=tax_spp).max())]\n",
    "                xflax = 'not present'\n",
    "            # Change landings prior to cutoff value\n",
    "            priorImportance.loc[dict(country=c,species=axx)] = sppcutoff\n",
    "            tmp_spp += list(axx)\n",
    "            #print(\"Low \"+t+\" changed \"+c+\", spp are \"+xflax)\n",
    "            #print(axx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified index and columns\n",
    "scorez = list(np.unique(priorImportance).astype(int).astype(str))\n",
    "tradeweightcounts = pd.DataFrame(index=priorImportance.country, columns=scorez).fillna(0)\n",
    "for c in priorImportance.country.to_numpy():\n",
    "    colz, valz = np.unique(priorImportance[priorImportance.country==c,:],return_counts=True)\n",
    "    tradeweightcounts.loc[c,colz.astype(int).astype(str)] = valz\n",
    "#tradeweightcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in species in field data\n",
    "field_tmp = np.array(['Atlantoraja cyclhophora', 'Bathtoshia centroura',\n",
    "       'Callorynchus callorynchus',\n",
    "       'Dasyatis hypostigma', 'Fontitrygon geijskesi',\n",
    "       'Hypanus bethalutzae', 'Mobula hypostoma', 'Narcine brasiliensis',\n",
    "       'Pseudobatos horkelii', 'Pteroplatytrygon violacae',\n",
    "       'Rhinoptera brasilisensis', 'Rioraja agassizi',\n",
    "       'Scyliorhinus haekelii', 'Squalus albicaudus', 'Squatina occulta',\n",
    "       'Zapteryx brevirostris','Apristurus brunneus', 'Bathyraja aleutica',\n",
    "       'Bathyraja interrupta', 'Bathyraja murrayi',\n",
    "       'Cephaloscyllium isabellum', 'Gollum attenuatus',\n",
    "       'Oxynotus bruniensis', 'Rostroraja eglanteria'])\n",
    "for s in field_tmp:\n",
    "    if s not in tmp_spp:\n",
    "        tmp_spp+=[s]\n",
    "\n",
    "# Species to drop = have prior importance <=1 AND are not actually observed as taxon to the species level\n",
    "drop_spp = drop_spp[np.array([x not in tmp_spp for x in drop_spp])]\n",
    "\n",
    "#\"\"\"\n",
    "# Drop rare and unreported species\n",
    "speciesCountryIDMap = speciesCountryIDMap.drop_sel(species=drop_spp)\n",
    "priorImportance = priorImportance.drop_sel(species=drop_spp)\n",
    "logProbPrior = logProbPrior.drop_sel(species=drop_spp)\n",
    "SpeciesCommodityMap = SpeciesCommodityMap.drop_sel(species=drop_spp)\n",
    "# Add in unreporting countries\n",
    "\n",
    "# = = = = = = = = = = = = = = After species drop = = = = = = = = = = = = = #\n",
    "\n",
    "# Vectors\n",
    "allCatch = tmp[\"allCatch\"]\n",
    "cindx = allCatch>0\n",
    "allCatch = allCatch[cindx]\n",
    "logCatch = np.log1p(tmp[\"allCatch\"])[cindx]\n",
    "species_ = logProbPrior.species.to_numpy()\n",
    "country_ = logProbPrior.country.to_numpy()\n",
    "CountryIDx = match(tmp[\"country\"][cindx], list(country_))\n",
    "year_ = [\"year_\" + str(x) for x in np.unique(tmp[\"year\"][cindx]).astype(int)]\n",
    "YearIDx = match(tmp[\"year\"][cindx], list(np.unique(tmp[\"year\"][cindx]).astype(int)))\n",
    "taxon_ = logProbPrior.taxon.to_numpy()\n",
    "TaxonIDx = match(tmp[\"LandingsID\"][cindx], list(taxon_))\n",
    "speciesCountryMap = speciesCountryIDMap.groupby(\"species\").max(\"taxon\")\n",
    "TaxonPRIOR = priorImportance.to_numpy()\n",
    "\n",
    "# Meat species\n",
    "#meat_mask = SpeciesCommodityMap.sel(commodity='meat',species=species_).to_numpy()\n",
    "meat_mask = 1*(SpeciesCommodityMap.sel(commodity=('fins'),species=species_)+SpeciesCommodityMap.sel(commodity=('meat'),species=species_)>0).to_numpy()\n",
    "meat_mask[meat_mask==0] = -9\n",
    "meat_mask[meat_mask==1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match FAO to observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset observed landings to match FAO countries\n",
    "Obsspp = np.sort(np.array(list(set(ObsLandings_.species.values).intersection(priorImportance.species.values))))\n",
    "Obscou = np.sort(np.array(list(set(ObsLandings_.country.values).intersection(priorImportance.country.values))))\n",
    "ObsLandings = ObsLandings_.sel(country=Obscou, species=Obsspp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tmp empty data to match dimension of full species compliment for observed countries\n",
    "tmpdata = priorImportance.copy()*-0\n",
    "tmpdata.loc[dict(country=ObsLandings.country, species=ObsLandings.species)] = ObsLandings.values\n",
    "ObsLandings = tmpdata.sel(country=Obscou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average total catch for target of softmax\n",
    "TotalCatch = np.array([allCatch[CountryIDx==i].sum() for i in range(speciesCountryIDMap.shape[0])])/len(year_)\n",
    "logTotalCatch = np.log(TotalCatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(taxon_[TaxonIDx[tindx == 0]][match(taxon_[TaxonIDx[tindx == 0]], list(species_))==None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = #\n",
    "\n",
    "# Make group vector\n",
    "group_ = srkey.group[match(species_,list(srkey.species_binomial))].to_numpy()\n",
    "# Make masks for trade sums\n",
    "shark_mask = 1*(group_=='sharks')\n",
    "ray_mask = 1*(group_=='rays')\n",
    "\n",
    "# Grab only aggregated taxa\n",
    "taxon_shortlist = taxon_[pd.Series(taxon_).str.count(\" \").to_numpy() == 0]\n",
    "\n",
    "# Split data index\n",
    "tindx = pd.Series(taxon_[TaxonIDx]).str.count(\" \").to_numpy() == 0\n",
    "# Split landings\n",
    "logReported_species_landings = logCatch[tindx == 0]\n",
    "logReported_taxon_landings = logCatch[tindx == 1]\n",
    "# Split country index\n",
    "country_spp_id = CountryIDx[tindx == 0]\n",
    "country_tax_id = CountryIDx[tindx == 1]\n",
    "# Split year index\n",
    "year_spp_id = YearIDx[tindx == 0]\n",
    "year_tax_id = YearIDx[tindx == 1]\n",
    "# Split species index\n",
    "species_spp_id = match(taxon_[TaxonIDx[tindx == 0]], list(species_))\n",
    "# Split taxon index\n",
    "# taxon_tax_id = TaxonIDx[tindx==1]\n",
    "taxon_tax_id = match(taxon_[TaxonIDx[tindx == 1]], list(taxon_shortlist))\n",
    "\n",
    "\n",
    "\n",
    "# Make dataframes for later\n",
    "sdata = pd.DataFrame(\n",
    "    {\n",
    "        \"logReported_species_landings\": logReported_species_landings,\n",
    "        \"species_spp_id\": species_spp_id,\n",
    "        \"country_spp_id\": country_spp_id,\n",
    "        \"year_spp_id\": year_spp_id,\n",
    "        \"country\": country_[country_spp_id],\n",
    "        \"year\": np.array(year_)[year_spp_id],\n",
    "        \"species\": species_[species_spp_id],\n",
    "    }\n",
    ")\n",
    "txdata = pd.DataFrame(\n",
    "    {\n",
    "        \"logReported_taxon_landings\": logReported_taxon_landings,\n",
    "        \"taxon_tax_id\": taxon_tax_id,\n",
    "        \"country_tax_id\": country_tax_id,\n",
    "        \"year_tax_id\": year_tax_id,\n",
    "        \"country\": country_[country_tax_id],\n",
    "        \"year\": np.array(year_)[year_tax_id],\n",
    "        \"taxon\": taxon_shortlist[taxon_tax_id],\n",
    "    }\n",
    ")\n",
    "txdata = txdata.loc[match(txdata.taxon, list(taxon_shortlist)) != None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial mask of species matched to possible taxon\n",
    "InitTaxonMASK = speciesCountryIDMap.copy()\n",
    "# Create empty mask to store observed taxa as possible\n",
    "TaxonMASK = InitTaxonMASK*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reported taxa by country\n",
    "Obs_tax_data = np.exp(txdata.drop(columns=['year','year_tax_id','country_tax_id','taxon_tax_id']\n",
    "          ).groupby(['country','taxon']).mean()).rename(columns={\"logReported_taxon_landings\": \"Reported_landings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratre over countries\n",
    "for c in country_:\n",
    "    try:\n",
    "        # Iterate over observed taxa and make possible\n",
    "        taxes = Obs_tax_data.loc[c].index.values\n",
    "        for t in taxes:\n",
    "            for s in species_:\n",
    "                TaxonMASK.loc[dict(country=c,species=s,taxon=t)]=InitTaxonMASK.loc[dict(country=c,species=s,taxon=t)]\n",
    "    except:\n",
    "        #print(c)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update trade and landing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab trade weights\n",
    "wdata = pd.read_csv(bd + \"trade_weights.csv\").copy()\n",
    "# Empty array to hold values\n",
    "tradeweights = pd.DataFrame(index=country_, columns=species_).fillna(0).to_numpy()\n",
    "tradeweights.flags.writeable = True\n",
    "\n",
    "# Make xarray and add importer dimension\n",
    "tradeweights = (xr.DataArray(tradeweights, dims=('exporter', 'species'))\n",
    "                .assign_coords({\"exporter\": country_,\"species\": species_})\n",
    "                .expand_dims(importer=country_,axis=2)\n",
    "               )\n",
    "# Make a copy to make it writable\n",
    "tradeweights = tradeweights.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in values\n",
    "for index, row in wdata.iterrows():\n",
    "    try:\n",
    "        # Common export logOdds\n",
    "        tradeweights.loc[dict(exporter=row.exporter,species=row.species)] = row.tradeweight\n",
    "        # Domestic consumption logOdds\n",
    "        tradeweights.loc[dict(exporter=row.exporter,species=row.species,importer=row.exporter)] = row.domesticweight\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make priors using relative odds to proportion total landings\n",
    "SppPRIOR = priorImportance.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified index and columns\n",
    "scorez = list(np.unique(SppPRIOR).astype(int).astype(str))\n",
    "tradeweightcounts = pd.DataFrame(index=country_, columns=scorez).fillna(0)\n",
    "\n",
    "for c in country_:\n",
    "    colz, valz = np.unique(SppPRIOR[country_==c,:],return_counts=True)\n",
    "    tradeweightcounts.loc[c,colz.astype(int).astype(str)] = valz\n",
    "#tradeweightcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add updates to landing priors - NOV 2024\n",
    "for index, row in wdata.iterrows():\n",
    "    SppPRIOR[country_==row.exporter,species_==row.species] = row.landweight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-weight scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the expected proportions of species in each country\n",
    "tmp = pd.DataFrame(np.exp(SppPRIOR))\n",
    "proportions_df = tmp.div(tmp.sum(axis=1), axis=0).fillna(0)\n",
    "# Calculate log-odds for each proportion\n",
    "# Adding a small constant to avoid log(0)\n",
    "epsilon = 1e-6\n",
    "SppPRIORadj = round(np.log(proportions_df / (1 - proportions_df + epsilon) + epsilon)+6).values\n",
    "\n",
    "# Cut down taxon MASK to match taxon_shortlist dimensions\n",
    "#TaxonMASK_S = TaxonMASK[:, :, match(taxon_shortlist, list(taxon_))]\n",
    "TaxonMASK_S = TaxonMASK.sel(taxon=taxon_shortlist)\n",
    "TaxonMASK_Sx = TaxonMASK_S.to_numpy()\n",
    "\n",
    "# Negative mask for log-odds zeros\n",
    "negval = -9\n",
    "TaxonMASK_NEG = TaxonMASK_S.copy().to_numpy()\n",
    "TaxonMASK_NEG[TaxonMASK_NEG==0] = negval\n",
    "\n",
    "\n",
    "# Species weight for countries with no aggregations - huge log-odds so p(species ID)=1 where needed\n",
    "NoTaxaSppWT = np.zeros(SppPRIOR.shape)\n",
    "NoTaxaSppWT[(TaxonMASK_NEG != negval).sum(1).sum(1) == 0, :] = abs(negval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(SppPRIOR[SppPRIOR > -10], SppPRIORadj[SppPRIOR > -10])\n",
    "#x = np.linspace(-4, 4, 100)\n",
    "#y = x\n",
    "#plt.plot(x, y, linestyle='--', color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(['Carcharhinus acronotus', 'Carcharhinus brevipinna',\n",
    "       'Dasyatis hypostigma', 'Heptranchias perlo',\n",
    "       'Narcine brasiliensis', 'Rhinoptera bonasus',\n",
    "       'Rhizoprionodon lalandii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified index and columns\n",
    "scorez = list(np.unique(SppPRIOR).astype(int).astype(str))\n",
    "tradeweightcounts = pd.DataFrame(index=country_, columns=scorez).fillna(0)\n",
    "\n",
    "for c in country_:\n",
    "    colz, valz = np.unique(SppPRIOR[country_==c,:],return_counts=True)\n",
    "    tradeweightcounts.loc[c,colz.astype(int).astype(str)] = valz\n",
    "#tradeweightcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match landings and trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make fdata table to merge with trade model\n",
    "fdata = pd.DataFrame(\n",
    "    {\n",
    "        \"year\": YearIDx + 2012,\n",
    "        \"country_code\": country_[CountryIDx],\n",
    "        \"species\": taxon_[TaxonIDx],\n",
    "        \"landed_weight\": allCatch,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add shark/ray group for each taxon in landings\n",
    "tmp_taxon = fdata.species.unique()\n",
    "tmp_group = []\n",
    "\n",
    "for tx in tmp_taxon:\n",
    "    # taxon at species level\n",
    "    if tx in srkey.species_binomial.to_numpy():\n",
    "        tmp_group += [srkey.group[srkey.species_binomial==tx].values[0]]\n",
    "    elif tx in srkey.Genus.to_numpy():\n",
    "        tmp_group += [srkey.group[srkey.Genus==tx].values[0]]\n",
    "    elif tx in srkey.Family.to_numpy():\n",
    "        tmp_group += [srkey.group[srkey.Family==tx].values[0]]\n",
    "    elif tx in srkey.Order.to_numpy():\n",
    "        tmp_group += [srkey.group[srkey.Order==tx].values[0]]\n",
    "    elif tx in ['Sphyrnidae','Selachimorpha']:\n",
    "        tmp_group += ['sharks']\n",
    "    elif tx in ['Elasmobranchii']:\n",
    "        tmp_group += ['elasmos']\n",
    "    else:\n",
    "        print(tx)\n",
    "fdata['group'] = np.array(tmp_group)[match(fdata.species,list(tmp_taxon))]\n",
    "\n",
    "\n",
    "\n",
    "## CHECK THAT ADDITIONAL ELASMOS ARE OK WITH RE-EXPORT CALCULATIONS. \n",
    "## CHECK ALL LANDINGS AND TRADE DATA TO ENSURE SAME YEAR-LEVEL OBSERVATIONS\n",
    "\n",
    "\n",
    "# ## Import commodity code table\n",
    "\n",
    "# Import taxonomic match table for BACI commodity codes and species (MASK)\n",
    "cdata = pd.read_csv(bd + \"comm.code.taxon.match.csv\")\n",
    "\n",
    "# ## Load BACI keys\n",
    "\n",
    "# Import BACI commodity code key\n",
    "ckey = pd.read_csv(bd + \"product_codes_HS12_V202102.csv\")\n",
    "ckey17 = pd.read_csv(bd + \"product_codes_HS17_V202102.csv\")\n",
    "\n",
    "\n",
    "# Import country keys\n",
    "kdata = pd.read_csv(bd + \"country_codes_V202409.csv\")\n",
    "kdata.country_code = kdata.country_code.values.astype(int)\n",
    "\n",
    "# TWN doesn't have an ISO code\n",
    "kdata.loc[\n",
    "    kdata.country_name_full == \"Other Asia, not elsewhere specified\", \"iso_3digit_alpha\"\n",
    "] = \"TWN\"\n",
    "\n",
    "# ## Load BACI seafood trade\n",
    "\n",
    "# Import overall trade from BACI data\n",
    "odata = pd.read_csv(bd + \"baci.seafood_12-19_ij_all.csv\")\n",
    "\n",
    "# Make them numeric\n",
    "odata.exporter_i = odata.exporter_i.values.astype(int)\n",
    "odata.importer_j = odata.importer_j.values.astype(int)\n",
    "\n",
    "# Add country codes\n",
    "\n",
    "odata[\"ISOex_i\"] = kdata.iso_3digit_alpha.values[\n",
    "    match(list(odata.exporter_i.values), list(kdata.country_code.values))\n",
    "]\n",
    "odata[\"ISOim_j\"] = kdata.iso_3digit_alpha.values[\n",
    "    match(list(odata.importer_j.values), list(kdata.country_code.values))\n",
    "]\n",
    "\n",
    "\n",
    "# ## Load BACI meat trade\n",
    "\n",
    "# Import BACI data\n",
    "#tdata = pd.read_csv(bd + \"baci.elasmo_HS12_2012-2017.csv\")\n",
    "tdata = pd.read_csv(bd + \"baci_HS12-19_elasmo.csv\")\n",
    "tdata = tdata[tdata['quantity_q'].notna()]\n",
    "tdata = tdata[tdata['quantity_q']!='           NA']\n",
    "\n",
    "# Make them numeric\n",
    "tdata.exporter_i = tdata.exporter_i.values.astype(int)\n",
    "tdata.importer_j = tdata.importer_j.values.astype(int)\n",
    "tdata.quantity_q = tdata.quantity_q.values.astype(float)\n",
    "\n",
    "# Temporary change of code for Italy\n",
    "tdata.loc[tdata.exporter_i == 381, \"exporter_i\"] = 380\n",
    "tdata.loc[tdata.importer_j == 381, \"importer_j\"] = 380\n",
    "\n",
    "# Add country names for imports/exports\n",
    "tdata[\"ISOex_i\"] = kdata.iso_3digit_alpha.values[\n",
    "    match(list(tdata.exporter_i.values), list(kdata.country_code.values))\n",
    "]\n",
    "tdata[\"ISOim_j\"] = kdata.iso_3digit_alpha.values[\n",
    "    match(list(tdata.importer_j.values), list(kdata.country_code.values))\n",
    "]\n",
    "\n",
    "# Add explicit code descriptions\n",
    "tdata['hs_description'] = ckey17.description.values[match(tdata[\"hscode_k\"],list(ckey17.code.values))]\n",
    "\n",
    "# Drop all trade on code 30571\n",
    "tdata = tdata[tdata[\"hscode_k\"]!=30571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(filter(lambda x: 'fish' in x, ckey.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make fresh/frozen fins dummy\n",
    "tmp = np.array([0]*len(tdata['hs_description']))\n",
    "tmp[tdata[\"hscode_k\"]==30292] = 1\n",
    "tmp[tdata[\"hscode_k\"]==30392] = 1\n",
    "tdata['fins'] = tmp\n",
    "\n",
    "# Make rays dummy\n",
    "tdata['rays'] = np.array(['rays' in l for l in tdata['hs_description']])*1\n",
    "# Make 30488 (grouped code) sharks\n",
    "maskx = tdata.hscode_k==30488\n",
    "tdata.loc[maskx,'rays'] = 0\n",
    "\n",
    "# Add shark or ray group\n",
    "tmp = np.array(['sharks']*len(tdata['rays']))\n",
    "tmp[tdata['rays']==1] = 'rays'\n",
    "tdata['group'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight for fins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab sharks in years that have fresh/frozen fins separated\n",
    "tdata_17 = tdata.copy()[(tdata.year_t>=tdata[tdata.fins==1].year_t.min()) & (tdata.group=='sharks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total exports of fins and meat per year, exporter, importer combo\n",
    "tmp = tdata_17.groupby([\"ISOex_i\",\"ISOim_j\",\"year_t\",\"fins\"]).sum().reset_index()\n",
    "# Grab 30292 and 30392 (fins) commodity\n",
    "tmp_fins = tmp.copy()[tmp.fins==1]\n",
    "# Sum over total per exporter, importer combo\n",
    "tmp_sum = tmp[[\"ISOex_i\",\"ISOim_j\",\"quantity_q\"]].groupby([\"ISOex_i\",\"ISOim_j\"]).sum()\n",
    "# Sum fins over total per year, exporter, importer\n",
    "tmp_fins_sum = tmp_fins[[\"ISOex_i\",\"ISOim_j\",\"quantity_q\"]].groupby([\"ISOex_i\",\"ISOim_j\"]).sum()\n",
    "# Grab proportion of fins where there are any\n",
    "tmp_fin_props = (tmp_fins_sum/tmp_sum).reset_index()\n",
    "# Make zero fins where there are none\n",
    "maskx = tmp_fin_props.quantity_q.isna()\n",
    "tmp_fin_props.loc[maskx,'quantity_q'] = 0\n",
    "# Convert to proportions of meat\n",
    "tmp_meat_props = tmp_fin_props.copy()\n",
    "tmp_meat_props['prop_sharks'] = 1-tmp_meat_props.quantity_q\n",
    "tmp_meat_props = tmp_meat_props.drop(columns=['quantity_q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata_old = tdata.copy()\n",
    "# Iterate over exporter/importer combos\n",
    "for i in range(tmp_meat_props.shape[0]):\n",
    "    exi = tmp_meat_props.ISOex_i[i]\n",
    "    imi = tmp_meat_props.ISOim_j[i]\n",
    "    shark_prop = tmp_meat_props.prop_sharks[i]\n",
    "    # Re-scale observed sharks pre 2017 to remove fins fraction from fresh or frozen sharks\n",
    "    maskx = ((tdata.year_t<2017) & (tdata.ISOex_i==exi) & (tdata.ISOim_j==imi)&(tdata.group=='sharks'))\n",
    "    tdata.loc[maskx,'quantity_q'] = tdata.loc[maskx,'quantity_q']*shark_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(tdata_old.quantity_q,tdata.quantity_q)\n",
    "#plt.xlabel('All shark trade')\n",
    "#plt.ylabel('Adjusted shark trade')\n",
    "#plt.title('Shark trade with fins removed 2012-2017');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to live weights\n",
    "tdata['estimated_live_weight'] = tdata.quantity_q\n",
    "# Sharks conversion\n",
    "tmpmask = tdata.group=='sharks'\n",
    "tdata.loc[tmpmask,'estimated_live_weight'] = tdata.loc[tmpmask,'estimated_live_weight']*2\n",
    "# Rays conversion\n",
    "tmpmask = tdata.group=='rays'\n",
    "tdata.loc[tmpmask,'estimated_live_weight'] = tdata.loc[tmpmask,'estimated_live_weight']*1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reset biggest_countries to include only those with landings\n",
    "biggest_countries = country_\n",
    "\n",
    "# - - - - - - - - - - - Add BACI total seafood trade\n",
    "total_seafood_trade = (\n",
    "    odata[\n",
    "        ((odata.ISOex_i).isin(biggest_countries))\n",
    "        & ((odata.ISOim_j).isin(biggest_countries))\n",
    "    ]\n",
    "    .groupby([\"ISOex_i\", \"ISOim_j\"])\n",
    "    .sum()[\"ij_total\"]\n",
    "    .reset_index()\n",
    "    .set_index(\"ISOex_i\")\n",
    "    .pivot(columns=\"ISOim_j\")\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .fillna(0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reset biggest_countries to include only those with landings\n",
    "biggest_countries = country_\n",
    "\n",
    "# - - - - - - - - - - - Add BACI total seafood trade\n",
    "total_seafood_trade = (\n",
    "    odata[\n",
    "        ((odata.ISOex_i).isin(biggest_countries))\n",
    "        & ((odata.ISOim_j).isin(biggest_countries))\n",
    "    ]\n",
    "    .groupby([\"ISOex_i\", \"ISOim_j\"])\n",
    "    .sum()[\"ij_total\"]\n",
    "    .reset_index()\n",
    "    .set_index(\"ISOex_i\")\n",
    "    .pivot(columns=\"ISOim_j\")\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .fillna(0.0)\n",
    ")\n",
    "\n",
    "# Better country labels\n",
    "biggest_countries_long = kdata.country_name_abbreviation[\n",
    "    [list(kdata.iso_3digit_alpha).index(x) for x in biggest_countries]\n",
    "].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with re-exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REEXPORTS - NEED TO CHECK THAT RAYS ARE COOL HERE TOO\n",
    "#\n",
    "# Currently removes trade that has no possible catch.\n",
    "#\n",
    "# NB:\n",
    "#\n",
    "# 1. Assumes catches in year t are traded in year t\n",
    "\n",
    "# Pre-removals copy\n",
    "tdata_copy = tdata.copy()\n",
    "# Unique country list\n",
    "tmp_c = np.unique(np.array(list(tdata.ISOex_i)+list(tdata.ISOim_j)))\n",
    "# Unique commodity codes\n",
    "tmp_u = tdata.group.unique()\n",
    "# Landings per country per year per commodity\n",
    "tmp_l = fdata.groupby([\"country_code\",\"year\",\"group\"]).sum().reset_index().sort_values(\"landed_weight\", ascending=False)\n",
    "\n",
    "\n",
    "# Empty list of identified re-exports\n",
    "tmp = []\n",
    "\n",
    "# ====================== Remove re-exports from trade =========================== #\n",
    "# Iterate over years\n",
    "for y in tdata.year_t.unique():\n",
    "    # Grab values for year y \n",
    "    trad_ = tdata[tdata.year_t==y].groupby([\"ISOex_i\",'year_t','group']).sum().reset_index().sort_values(\"estimated_live_weight\", ascending=False)\n",
    "    # Grab total trade for year y\n",
    "    trad = trad_.groupby([\"ISOex_i\",'year_t']).sum().reset_index().sort_values(\"estimated_live_weight\", ascending=False)\n",
    "    # Grab group trade for year y\n",
    "    trad_s = trad_[trad_.group=='sharks']\n",
    "    trad_r = trad_[trad_.group=='rays']\n",
    "    # Grab total landings for year y\n",
    "    land = tmp_l[tmp_l.year==y]\n",
    "    # Grab possible group landings for year y\n",
    "    land_s = land[land.group=='sharks']\n",
    "    land_r = land[land.group=='rays']\n",
    "    land_e = land[land.group=='elasmos']\n",
    "    # Iteratre over countries\n",
    "    for e in tmp_c:\n",
    "        if e in land.country_code.unique() and e in trad.ISOex_i.unique():\n",
    "            # Grab values for exporter e in year y\n",
    "            tx = trad[trad.ISOex_i==e]\n",
    "            tx_s = trad_s[trad_s.ISOex_i==e]\n",
    "            tx_r = trad_r[trad_r.ISOex_i==e]\n",
    "            # Grab landings\n",
    "            lx = land[land.country_code==e]\n",
    "            lx_s = land_s[land_s.country_code==e]\n",
    "            lx_r = land_r[land_r.country_code==e]\n",
    "            lx_e = land_e[land_e.country_code==e]\n",
    "\n",
    "            # If no catches to support trade, make trade zero to remove re-exports\n",
    "            # Do this first because no catches of any kind trump group specifics\n",
    "            # justified because the project is about assigning catches within the trade to specific nations\n",
    "            if sum(lx.landed_weight)==0 and sum(tx.estimated_live_weight)>0:\n",
    "                tmp += [sum(tx.estimated_live_weight)]\n",
    "                maskx = (tdata.ISOex_i==e) & (tdata.year_t==y)\n",
    "                tdata.loc[maskx,'estimated_live_weight'] = 0\n",
    "                \n",
    "            # If no catches (group+elasmos) to support shark trade, make trade zero to remove re-exports: \n",
    "            if sum(lx_s.landed_weight+lx_e.landed_weight)==0 and sum(tx_s.estimated_live_weight)>0:\n",
    "                tmp += [sum(tx_s.estimated_live_weight)]\n",
    "                maskx = (tdata.ISOex_i==e) & (tdata.year_t==y) & (tdata.group=='sharks')\n",
    "                tdata.loc[maskx,'estimated_live_weight'] = 0\n",
    "                \n",
    "            # If no catches (group+elasmos) to support ray trade, make trade zero to remove re-exports:\n",
    "            if sum(lx_r.landed_weight+lx_e.landed_weight)==0 and sum(tx_r.estimated_live_weight)>0:\n",
    "                tmp += [sum(tx_r.estimated_live_weight)]\n",
    "                maskx = (tdata.ISOex_i==e) & (tdata.year_t==y) & (tdata.group=='rays')\n",
    "                tdata.loc[maskx,'estimated_live_weight'] = 0\n",
    "                \n",
    "            # If trade more than catches, make proportional within allowable group\n",
    "            elif sum(lx.landed_weight)<sum(tx.estimated_live_weight):\n",
    "                tmp += [sum(tx.estimated_live_weight)]\n",
    "                # Grab proportion\n",
    "                rrx = sum(lx.landed_weight)/sum(tx.estimated_live_weight)\n",
    "                # Re-scale trade to proportion of total landings\n",
    "                mask_s = (tdata.ISOex_i==e) & (tdata.year_t==y) & (tdata.group=='sharks')\n",
    "                tdata.loc[mask_s,'estimated_live_weight'] = tdata.loc[mask_s,'estimated_live_weight']*rrx\n",
    "                mask_r = (tdata.ISOex_i==e) & (tdata.year_t==y) & (tdata.group=='rays')\n",
    "                tdata.loc[mask_r,'estimated_live_weight'] = tdata.loc[mask_r,'estimated_live_weight']*rrx\n",
    "        else:\n",
    "            mask = ((tdata.ISOex_i==e) & (tdata.year_t==y))\n",
    "            tdata.loc[mask,'estimated_live_weight'] = 0\n",
    "            #print(e,y)        \n",
    "\n",
    "# ## Restrict landings, seafood trade and meat trade to biggest countries\n",
    "\n",
    "# Original\n",
    "tmp_x = (tdata_copy.estimated_live_weight)\n",
    "# Updated\n",
    "tmp_y = (tdata.estimated_live_weight)\n",
    "# Countries with trade reduced\n",
    "iredux = (tdata_copy.estimated_live_weight-tdata.estimated_live_weight)>1\n",
    "# Grap re-exports data\n",
    "ReExports = pd.DataFrame(zip(tmp_x[iredux],tmp_y[iredux],tdata.ISOex_i[iredux].to_numpy(),tdata_copy.year_t[iredux],tdata_copy.group[iredux]),columns=['Original','Reduced','exporter','year','group'])\n",
    "ReExports['Net_diff'] = ReExports.Original-ReExports.Reduced\n",
    "ReExports['Exporter'] = kdata.country_name_abbreviation[[list(kdata.iso_3digit_alpha).index(x) for x in ReExports.exporter]].to_numpy()\n",
    "\n",
    "# Table of re-exporting countries\n",
    "tmp = ReExports.groupby(['Exporter']).sum().sort_values(by='Net_diff',ascending=False).drop(columns='exporter')\n",
    "tmp.to_csv('ReExport_totals_AUGM.csv')\n",
    "# Local augmented re-exports\n",
    "ReExports_AUGM = ReExports\n",
    "\n",
    "# = = = = = = = = = = = = = #\n",
    "# Remove zeros from trade\n",
    "tdata = tdata[tdata.estimated_live_weight!=0]\n",
    "\n",
    "# = = = = = = = = = = = = = #\n",
    "# Remove fins\n",
    "tdata = tdata[tdata['product']=='meat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imprt FAO trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAO trade data\n",
    "rdata = pd.read_csv(bd + \"FAO_elasmo.csv\")\n",
    "# Drop rows with zero trade\n",
    "rdata = rdata[rdata.trade_quantity>0]\n",
    "# Drop rows outside of 2012-2019\n",
    "rdata = rdata[rdata.year<=2019]\n",
    "# Drop NA\n",
    "rdata = rdata[rdata.trade_quantity.notna()]\n",
    "rdata = rdata[rdata.commodity_fao.notna()]\n",
    "\n",
    "# Drop other trade\n",
    "rdata = rdata[rdata.commodity_fao!='Shark fins, smoked, dried, whether or not salted, etc.']\n",
    "rdata = rdata[rdata.commodity_fao!='Shark fins, prepared or preserved']\n",
    "rdata = rdata[rdata.commodity_fao!='Shark fins, frozen']\n",
    "rdata = rdata[rdata.commodity_fao!='Shark fins, salted and in brine but not dried or smoked']\n",
    "rdata = rdata[rdata.commodity_fao!='Shark fins, dried, unsalted']\n",
    "rdata = rdata[rdata.commodity_fao!='Sharks, dried, whether or not salted, but not smoked']\n",
    "rdata = rdata[rdata.commodity_fao!='Shark oil']\n",
    "rdata = rdata[rdata.commodity_fao!='Shark liver oil']\n",
    "rdata = rdata[rdata.commodity_fao!='Sharks, fillets, dried, salted or in brine']\n",
    "\n",
    "# Drop countries outside of top traders\n",
    "tindx = (match(rdata.reporting_country.values,list(biggest_countries_long))[\n",
    "         match(rdata.reporting_country.values,list(biggest_countries_long))!=None]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab codes\n",
    "FAOcodes = pd.DataFrame({'code':rdata.commodity_fao.unique()})\n",
    "FAOcodes['group'] = np.array(['rays','sharks'])[FAOcodes.code.str.contains('shark').values*1]\n",
    "FAOcodes.group[(FAOcodes.code.str.contains('shark',case=False, regex=False, na=False).values*1\n",
    "                +FAOcodes.code.str.contains('ray',case=False, regex=False, na=False).values*1)==2] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write external key\n",
    "pd.DataFrame(columns=FAOcodes.code,index=srkey.species_binomial).to_csv('FAO_elasmo_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 59, 59, 61], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Albania', 'Algeria', 'Andorra', 'Angola', 'Argentina',\n",
       "       'Australia', 'Austria', 'Azerbaijan', 'Barbados', 'Belarus',\n",
       "       'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China',\n",
       "       'Colombia', 'Costa Rica', 'Croatia', 'Curaçao', 'Cyprus',\n",
       "       'Czechia', \"Côte d'Ivoire\",\n",
       "       \"Democratic People's Republic of Korea\", 'Denmark', 'Ecuador',\n",
       "       'Egypt', 'El Salvador', 'Estonia', 'Faroe Islands', 'Fiji',\n",
       "       'France', 'Germany', 'Ghana', 'Greece', 'Guatemala', 'Honduras',\n",
       "       'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Italy',\n",
       "       'Japan', 'Kazakhstan', 'Latvia', 'Libya', 'Lithuania',\n",
       "       'Luxembourg', 'Malaysia', 'Malta', 'Marshall Islands', 'Mauritius',\n",
       "       'Mexico', 'Micronesia (Federated States of)', 'Montenegro',\n",
       "       'Morocco', 'Namibia', 'Netherlands (Kingdom of the)',\n",
       "       'New Zealand', 'Nicaragua', 'Nigeria', 'Norway', 'Oman', 'Panama',\n",
       "       'Peru', 'Philippines', 'Poland', 'Portugal', 'Republic of Korea',\n",
       "       'Republic of Moldova', 'Romania', 'Russian Federation', 'Rwanda',\n",
       "       'Saint Pierre and Miquelon', 'Senegal', 'Serbia', 'Sierra Leone',\n",
       "       'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'Spain',\n",
       "       'Suriname', 'Sweden', 'Switzerland', 'Taiwan Province of China',\n",
       "       'Thailand', 'Timor-Leste', 'Tonga', 'Trinidad and Tobago',\n",
       "       'Tunisia', 'Turks and Caicos Islands', 'Türkiye', 'Uganda',\n",
       "       'Ukraine', 'United Arab Emirates',\n",
       "       'United Kingdom of Great Britain and Northern Ireland',\n",
       "       'United Republic of Tanzania', 'United States of America',\n",
       "       'Uruguay', 'Vanuatu', 'Viet Nam', 'Yemen', 'Bahamas',\n",
       "       'Bosnia and Herzegovina', 'Botswana', 'Cameroon',\n",
       "       'China, Hong Kong SAR', 'Cuba', 'Dominican Republic',\n",
       "       'Equatorial Guinea', 'Grenada', 'Israel', 'Madagascar', 'Mali',\n",
       "       'Papua New Guinea', 'Saint Kitts and Nevis', 'South Sudan',\n",
       "       'Sri Lanka', 'Cabo Verde', 'Gabon', 'Guinea', 'Guyana', 'Lesotho',\n",
       "       'Pakistan', 'Paraguay', 'Somalia', 'Turkmenistan', 'Benin',\n",
       "       'Burkina Faso', 'Burundi', 'Congo', 'Finland',\n",
       "       'Iran (Islamic Republic of)', 'Lebanon', 'Qatar', 'Saint Lucia',\n",
       "       'Uzbekistan', 'Bahrain', 'Bangladesh', 'Brunei Darussalam',\n",
       "       'Dominica', 'French Polynesia', 'Georgia', 'Mauritania',\n",
       "       'Saint Vincent and the Grenadines', 'Saudi Arabia', 'Seychelles',\n",
       "       'Antigua and Barbuda', 'Greenland', 'Kuwait', 'New Caledonia',\n",
       "       'Jamaica', 'Maldives', 'Mozambique', 'Tajikistan',\n",
       "       'Venezuela (Bolivarian Republic of)', 'Armenia', 'Bermuda',\n",
       "       'China, Macao SAR', 'Comoros', 'Eswatini', 'Iraq', 'Kenya',\n",
       "       'Liberia', 'Mongolia', 'Niger', 'North Macedonia', 'Sudan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata.reporting_country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reporting_country</th>\n",
       "      <th>commodity_fao</th>\n",
       "      <th>trade_flow</th>\n",
       "      <th>unit</th>\n",
       "      <th>year</th>\n",
       "      <th>trade_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Dogfish and other sharks nei (excl. Squalus ac...</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Dogfish and other sharks nei (excl. Squalus ac...</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2012</td>\n",
       "      <td>96.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Rays and skates (Rajidae), frozen</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2012</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Dogfish and other sharks nei (excl. Squalus ac...</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Sharks nei, fresh or chilled</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23184</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Dogfish, other sharks, rays and skates (Rajida...</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23185</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Rays and skates (Rajidae) meat, frozen</td>\n",
       "      <td>Exports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2019</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23187</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Rays and skates (Rajidae), frozen</td>\n",
       "      <td>Exports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2019</td>\n",
       "      <td>622.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23188</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Rays and skates (Rajidae), frozen</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23203</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>Rays and skates (Rajidae), fresh or chilled</td>\n",
       "      <td>Exports</td>\n",
       "      <td>Tonnes – net product weight</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4562 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reporting_country                                      commodity_fao  \\\n",
       "3               Albania  Dogfish and other sharks nei (excl. Squalus ac...   \n",
       "13              Algeria  Dogfish and other sharks nei (excl. Squalus ac...   \n",
       "17              Algeria                  Rays and skates (Rajidae), frozen   \n",
       "22              Andorra  Dogfish and other sharks nei (excl. Squalus ac...   \n",
       "27              Andorra                       Sharks nei, fresh or chilled   \n",
       "...                 ...                                                ...   \n",
       "23184          Viet Nam  Dogfish, other sharks, rays and skates (Rajida...   \n",
       "23185          Viet Nam             Rays and skates (Rajidae) meat, frozen   \n",
       "23187          Viet Nam                  Rays and skates (Rajidae), frozen   \n",
       "23188          Viet Nam                  Rays and skates (Rajidae), frozen   \n",
       "23203             Yemen        Rays and skates (Rajidae), fresh or chilled   \n",
       "\n",
       "      trade_flow                         unit  year  trade_quantity  \n",
       "3        Imports  Tonnes – net product weight  2012            9.00  \n",
       "13       Imports  Tonnes – net product weight  2012           96.00  \n",
       "17       Imports  Tonnes – net product weight  2012           34.00  \n",
       "22       Imports  Tonnes – net product weight  2012            7.00  \n",
       "27       Imports  Tonnes – net product weight  2012            1.00  \n",
       "...          ...                          ...   ...             ...  \n",
       "23184    Imports  Tonnes – net product weight  2019            0.13  \n",
       "23185    Exports  Tonnes – net product weight  2019           20.27  \n",
       "23187    Exports  Tonnes – net product weight  2019          622.14  \n",
       "23188    Imports  Tonnes – net product weight  2019            1.06  \n",
       "23203    Exports  Tonnes – net product weight  2019            3.00  \n",
       "\n",
       "[4562 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rays', 'sharks', 'Holocephalimorpha'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srkey.group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Superorder</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>species_binomial</th>\n",
       "      <th>EDGE Scientific name</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elasmobranchii</td>\n",
       "      <td>Batoidea</td>\n",
       "      <td>Myliobatiformes</td>\n",
       "      <td>Aetobatidae</td>\n",
       "      <td>Aetobatus</td>\n",
       "      <td>Aetobatus flagellum</td>\n",
       "      <td>Aetobatus flagellum</td>\n",
       "      <td>rays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elasmobranchii</td>\n",
       "      <td>Batoidea</td>\n",
       "      <td>Myliobatiformes</td>\n",
       "      <td>Aetobatidae</td>\n",
       "      <td>Aetobatus</td>\n",
       "      <td>Aetobatus laticeps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elasmobranchii</td>\n",
       "      <td>Batoidea</td>\n",
       "      <td>Myliobatiformes</td>\n",
       "      <td>Aetobatidae</td>\n",
       "      <td>Aetobatus</td>\n",
       "      <td>Aetobatus narinari</td>\n",
       "      <td>Aetobatus narinari</td>\n",
       "      <td>rays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elasmobranchii</td>\n",
       "      <td>Batoidea</td>\n",
       "      <td>Myliobatiformes</td>\n",
       "      <td>Aetobatidae</td>\n",
       "      <td>Aetobatus</td>\n",
       "      <td>Aetobatus narutobiei</td>\n",
       "      <td>Aetobatus flagellum</td>\n",
       "      <td>rays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elasmobranchii</td>\n",
       "      <td>Batoidea</td>\n",
       "      <td>Myliobatiformes</td>\n",
       "      <td>Aetobatidae</td>\n",
       "      <td>Aetobatus</td>\n",
       "      <td>Aetobatus ocellatus</td>\n",
       "      <td>Aetobatus narinari</td>\n",
       "      <td>rays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>Holocephali</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "      <td>Chimaeriformes</td>\n",
       "      <td>Rhinochimaeridae</td>\n",
       "      <td>Neoharriotta</td>\n",
       "      <td>Neoharriotta pinnata</td>\n",
       "      <td>Neoharriotta pinnata</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Holocephali</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "      <td>Chimaeriformes</td>\n",
       "      <td>Rhinochimaeridae</td>\n",
       "      <td>Neoharriotta</td>\n",
       "      <td>Neoharriotta pumila</td>\n",
       "      <td>Neoharriotta pumila</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>Holocephali</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "      <td>Chimaeriformes</td>\n",
       "      <td>Rhinochimaeridae</td>\n",
       "      <td>Rhinochimaera</td>\n",
       "      <td>Rhinochimaera africana</td>\n",
       "      <td>Rhinochimaera africana</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Holocephali</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "      <td>Chimaeriformes</td>\n",
       "      <td>Rhinochimaeridae</td>\n",
       "      <td>Rhinochimaera</td>\n",
       "      <td>Rhinochimaera atlantica</td>\n",
       "      <td>Rhinochimaera atlantica</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>Holocephali</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "      <td>Chimaeriformes</td>\n",
       "      <td>Rhinochimaeridae</td>\n",
       "      <td>Rhinochimaera</td>\n",
       "      <td>Rhinochimaera pacifica</td>\n",
       "      <td>Rhinochimaera pacifica</td>\n",
       "      <td>Holocephalimorpha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Class         Superorder            Order            Family  \\\n",
       "0     Elasmobranchii           Batoidea  Myliobatiformes       Aetobatidae   \n",
       "1     Elasmobranchii           Batoidea  Myliobatiformes       Aetobatidae   \n",
       "2     Elasmobranchii           Batoidea  Myliobatiformes       Aetobatidae   \n",
       "3     Elasmobranchii           Batoidea  Myliobatiformes       Aetobatidae   \n",
       "4     Elasmobranchii           Batoidea  Myliobatiformes       Aetobatidae   \n",
       "...              ...                ...              ...               ...   \n",
       "1214     Holocephali  Holocephalimorpha   Chimaeriformes  Rhinochimaeridae   \n",
       "1215     Holocephali  Holocephalimorpha   Chimaeriformes  Rhinochimaeridae   \n",
       "1216     Holocephali  Holocephalimorpha   Chimaeriformes  Rhinochimaeridae   \n",
       "1217     Holocephali  Holocephalimorpha   Chimaeriformes  Rhinochimaeridae   \n",
       "1218     Holocephali  Holocephalimorpha   Chimaeriformes  Rhinochimaeridae   \n",
       "\n",
       "              Genus         species_binomial     EDGE Scientific name  \\\n",
       "0         Aetobatus      Aetobatus flagellum      Aetobatus flagellum   \n",
       "1         Aetobatus       Aetobatus laticeps                      NaN   \n",
       "2         Aetobatus       Aetobatus narinari       Aetobatus narinari   \n",
       "3         Aetobatus     Aetobatus narutobiei      Aetobatus flagellum   \n",
       "4         Aetobatus      Aetobatus ocellatus       Aetobatus narinari   \n",
       "...             ...                      ...                      ...   \n",
       "1214   Neoharriotta     Neoharriotta pinnata     Neoharriotta pinnata   \n",
       "1215   Neoharriotta      Neoharriotta pumila      Neoharriotta pumila   \n",
       "1216  Rhinochimaera   Rhinochimaera africana   Rhinochimaera africana   \n",
       "1217  Rhinochimaera  Rhinochimaera atlantica  Rhinochimaera atlantica   \n",
       "1218  Rhinochimaera   Rhinochimaera pacifica   Rhinochimaera pacifica   \n",
       "\n",
       "                  group  \n",
       "0                  rays  \n",
       "1                  rays  \n",
       "2                  rays  \n",
       "3                  rays  \n",
       "4                  rays  \n",
       "...                 ...  \n",
       "1214  Holocephalimorpha  \n",
       "1215  Holocephalimorpha  \n",
       "1216  Holocephalimorpha  \n",
       "1217  Holocephalimorpha  \n",
       "1218  Holocephalimorpha  \n",
       "\n",
       "[1219 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup landings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out shark and ray trade\n",
    "tdata_cut = tdata[\n",
    "    ((tdata.ISOex_i).isin(biggest_countries))\n",
    "    & ((tdata.ISOim_j).isin(biggest_countries))\n",
    "]\n",
    "# dropping missing values\n",
    "tdata_cut = tdata_cut.drop(\"Unnamed: 0\", axis=\"columns\").dropna().reset_index(drop=True)\n",
    "# Summarize data by importer export commodity\n",
    "tdata_cut = tdata_cut.groupby([\"ISOex_i\", \"ISOim_j\", \"group\",'year_t']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average per year\n",
    "tdata_cut = (tdata_cut[[\"ISOex_i\", \"ISOim_j\", \"group\",\"year_t\",'quantity_q','estimated_live_weight']]\n",
    "             .groupby([\"ISOex_i\", \"ISOim_j\", \"group\"])\n",
    "             .mean()\n",
    "             .drop(columns=['year_t'])\n",
    "             .reset_index()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just care about whether it's a shark or ray, not if it's also fresh or frozen\n",
    "tdata_cut = tdata_cut.sort_values([\"ISOex_i\", \"ISOim_j\", \"group\"])\n",
    "\n",
    "# Shark data\n",
    "tdata_cut_sharks = (\n",
    "    tdata_cut[tdata_cut.group == \"sharks\"]\n",
    "    .groupby([\"ISOex_i\", \"ISOim_j\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ray data\n",
    "tdata_cut_rays = (\n",
    "    tdata_cut[tdata_cut.group == \"rays\"]\n",
    "    .groupby([\"ISOex_i\", \"ISOim_j\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load unreliability score\n",
    "\n",
    "unreliability_score = pd.read_csv(\n",
    "    bd + \"reporter_reliability_HS12_V202102.csv\",\n",
    "    usecols=[\"c\", \"q_unreliability_i\", \"q_unreliability_j\"],\n",
    ")\n",
    "\n",
    "# ITA changed code -- because, why not?\n",
    "unreliability_score.loc[unreliability_score.c == 381, \"c\"] = 380\n",
    "\n",
    "# grab ISO codes from odata\n",
    "unreliability_score = unreliability_score.rename(\n",
    "    columns={\"q_unreliability_i\": \"exporter\", \"q_unreliability_j\": \"importer\"}\n",
    ").merge(odata, left_on=\"c\", right_on=\"exporter_i\")\n",
    "unreliability_score = (\n",
    "    unreliability_score[\n",
    "        ((unreliability_score.ISOex_i).isin(biggest_countries))\n",
    "        & ((unreliability_score.ISOim_j).isin(biggest_countries))\n",
    "    ][[\"ISOex_i\", \"exporter\", \"importer\"]]\n",
    "    .groupby(\"ISOex_i\")\n",
    "    .first()\n",
    ")\n",
    "\n",
    "# Check for missing unreliability scores\n",
    "misx = biggest_countries[\n",
    "    np.array([x not in unreliability_score.index for x in biggest_countries])\n",
    "]\n",
    "# Fill missing unreliablity scores with maximum unreliability value\n",
    "tmp_maxval = max(unreliability_score.exporter)\n",
    "if len(misx) > 0:\n",
    "    for i in misx:\n",
    "        unreliability_score = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame({'exporter': [0], 'importer': [0]}, index=[i]),\n",
    "                unreliability_score,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "unreliability_score = unreliability_score.sort_index().fillna(tmp_maxval)\n",
    "unreliability_score = unreliability_score.reindex(\n",
    "    sorted(unreliability_score.columns), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup taxon masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count taxon aggregations\n",
    "ntax_country = (\n",
    "    txdata.groupby(by=([\"country\", \"taxon\"]))\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .groupby(\"country\")\n",
    "    .count()\n",
    "    .taxon\n",
    ")\n",
    "\n",
    "# Add Belize\n",
    "ntax_country[\"BLZ\"] = 0\n",
    "# Re-order to match country_\n",
    "ntax_country = ntax_country[country_]\n",
    "\n",
    "# Taxon by country groupings\n",
    "taxindx1 = (ntax_country <= 1).to_numpy()\n",
    "taxindx2 = (ntax_country == 2).to_numpy()\n",
    "taxindx3 = (ntax_country >= 3).to_numpy()\n",
    "\n",
    "# Create 3 dimensional mask\n",
    "TaxonMASK_t1 = TaxonMASK_Sx.copy()\n",
    "TaxonMASK_t2 = TaxonMASK_Sx.copy()\n",
    "TaxonMASK_t3 = TaxonMASK_Sx.copy()\n",
    "\n",
    "# Deactivate countries without <=1, 2, or >=3 taxon groups reported\n",
    "TaxonMASK_t1[taxindx1 == False, ...] = 0\n",
    "TaxonMASK_t2[taxindx2 == False, ...] = 0\n",
    "TaxonMASK_t3[taxindx3 == False, ...] = 0\n",
    "\n",
    "# Make sure Elasmos bin is positive in countries with no aggregations\n",
    "NoTaxAgg = (NoTaxaSppWT.sum(1)==0)*1\n",
    "TaxonMASK_Sx[NoTaxAgg!=1,:,list(taxon_shortlist).index('Elasmobranchii')] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `dims` and `coords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some countries can be missing from importers or exporters\n",
    "# indexing needs to take that into account\n",
    "# if we used `factorize`, that would be ignored\n",
    "\n",
    "country_to_idx_map = {country: index for index, country in enumerate(biggest_countries)}\n",
    "shark_exporter_idx = tdata_cut_sharks[\"ISOex_i\"].map(country_to_idx_map).to_numpy()\n",
    "shark_importer_idx = tdata_cut_sharks[\"ISOim_j\"].map(country_to_idx_map).to_numpy()\n",
    "ray_exporter_idx = tdata_cut_rays[\"ISOex_i\"].map(country_to_idx_map).to_numpy()\n",
    "ray_importer_idx = tdata_cut_rays[\"ISOim_j\"].map(country_to_idx_map).to_numpy()\n",
    "\n",
    "# You have to be careful when creating shark_trade_matrix:\n",
    "shark_trade_matrix = (\n",
    "    tdata_cut_sharks[[\"ISOex_i\", \"ISOim_j\", \"estimated_live_weight\"]]\n",
    "    .set_index(\"ISOex_i\")\n",
    "    .pivot(columns=\"ISOim_j\")\n",
    "    .droplevel(0, axis=\"columns\")\n",
    ")\n",
    "\n",
    "# Add missing exporters and importers\n",
    "missing_col = []\n",
    "for p in country_:\n",
    "    if not p in shark_trade_matrix.columns.values:\n",
    "        missing_col.append(p)\n",
    "missing_col = np.array(missing_col)\n",
    "shark_trade_matrix[missing_col] = np.NaN\n",
    "shark_trade_matrix = shark_trade_matrix[country_]\n",
    "missing_row = shark_trade_matrix.columns.difference(shark_trade_matrix.index)\n",
    "shark_trade_matrix = shark_trade_matrix.T\n",
    "shark_trade_matrix[missing_row] = np.NaN\n",
    "shark_trade_matrix = shark_trade_matrix[country_]\n",
    "shark_trade_matrix = shark_trade_matrix.T.sort_index().fillna(0)\n",
    "shark_trade_mask = shark_trade_matrix.to_numpy()\n",
    "shark_trade_mask[shark_trade_mask>0] = 1\n",
    "# Add domestic consumption\n",
    "np.fill_diagonal(shark_trade_mask,1)\n",
    "\n",
    "# You have to be careful when creating ray_trade_matrix:\n",
    "ray_trade_matrix = (\n",
    "    tdata_cut_rays[[\"ISOex_i\", \"ISOim_j\", \"estimated_live_weight\"]]\n",
    "    .set_index(\"ISOex_i\")\n",
    "    .pivot(columns=\"ISOim_j\")\n",
    "    .droplevel(0, axis=\"columns\")\n",
    ")\n",
    "\n",
    "# Add missing exporters and importers\n",
    "#missing_col = ray_trade_matrix.index.difference(ray_trade_matrix.columns)\n",
    "missing_col = []\n",
    "for p in country_:\n",
    "    if not p in ray_trade_matrix.columns.values:\n",
    "        missing_col.append(p)\n",
    "missing_col = np.array(missing_col)\n",
    "ray_trade_matrix[missing_col] = np.NaN\n",
    "ray_trade_matrix = ray_trade_matrix[country_]\n",
    "missing_row = ray_trade_matrix.columns.difference(ray_trade_matrix.index)\n",
    "ray_trade_matrix = ray_trade_matrix.T\n",
    "ray_trade_matrix[missing_row] = np.NaN\n",
    "ray_trade_matrix = ray_trade_matrix[country_]\n",
    "ray_trade_matrix = ray_trade_matrix.T.sort_index().fillna(0)\n",
    "ray_trade_mask = ray_trade_matrix.to_numpy()\n",
    "ray_trade_mask[ray_trade_mask>0] = 1\n",
    "# Add domestic consumption\n",
    "np.fill_diagonal(ray_trade_mask,1)\n",
    "\n",
    "# Species mask for possible trade (including domestic)\n",
    "trade_mask = ray_trade_mask[:,None,:]*((group_=='rays')[None,:,None])+shark_trade_mask[:,None,:]*((group_=='sharks')[None,:,None])\n",
    "trade_mask[trade_mask==0] = -9\n",
    "trade_mask[trade_mask>0] = 0\n",
    "# Remove species not used for meat\n",
    "#trade_mask = trade_mask+meat_mask[None,:,None]\n",
    "trade_mask[trade_mask<0] = -9\n",
    "\n",
    "# Mask for trade softmax to zero out species with all -9\n",
    "NoSPP_Mask = (((trade_mask==-9).sum(2)!=len(country_))*1)\n",
    "\n",
    "# Mask for blue shark relative odds importer preferences\n",
    "BSmask = np.zeros(shape=trade_mask[0].shape)\n",
    "BSmask[list(species_).index('Prionace glauca')] = -9\n",
    "\n",
    "# Better country labels\n",
    "biggest_countries_long = kdata.country_name_abbreviation[\n",
    "    [list(kdata.iso_3digit_alpha).index(x) for x in biggest_countries]\n",
    "].to_numpy()\n",
    "\n",
    "# Create matching tensor for priors\n",
    "SppPRIORadj_idx = SppPRIORadj.copy()\n",
    "# List of unique prior values\n",
    "priors_ = list(np.sort(np.unique(SppPRIORadj)))\n",
    "# Replace prior values with index to OddsCAT\n",
    "for i in range(len(SppPRIORadj_idx)):\n",
    "    SppPRIORadj_idx[i] = match(SppPRIORadj_idx[i],priors_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed data country index \n",
    "obs_exporter_idx = np.array([country_to_idx_map[x] for x in Obscou])\n",
    "\n",
    "# Tmp fix of priors set too low for observed species\n",
    "tmp = ((SppPRIOR[obs_exporter_idx,:]==-999) & (ObsLandings.values>0))\n",
    "\n",
    "for t in range(len(tmp.sum(1))):\n",
    "    if tmp[t].sum()>0:\n",
    "        tmpc = ObsLandings.country[t].values\n",
    "        tmps = ObsLandings.species[tmp[t]].values\n",
    "        tmpo = ObsLandings.sel(country=tmpc,species=tmps).values\n",
    "        tmpm = priorImportance.sel(country=tmpc,species=tmps).values\n",
    "        #print(tmpc,tmps,tmpo,tmpm)\n",
    "        # tmp fix of priors\n",
    "        SppPRIOR[country_==tmpc,np.isin(species_,tmps)] = 1\n",
    "        SppPRIORadj[country_==tmpc,np.isin(species_,tmps)] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in revision tradeweights with tradeIportance priors\n",
    "for e in country_:\n",
    "    for s in species_:\n",
    "        tradeweights.values[country_==c,species_==s,country_!=c] = tradeImportance.sel(country=e,species=s).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -999 with -9\n",
    "tradeweights.values[tradeweights==-999] = -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab bilateral trade weights\n",
    "bdata = pd.read_csv(bd + \"bilateral_trade.csv\").copy()\n",
    "\n",
    "# Update specific weights\n",
    "for r in bdata.itertuples():\n",
    "    tradeweights.values[country_==r.exporter,species_==r.species,country_==r.importer] = r.tradeweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "COORDS = {\n",
    "    \"exporter\": biggest_countries,\n",
    "    \"importer\": biggest_countries,\n",
    "    \"obs_exporter\": country_[obs_exporter_idx],\n",
    "    \"shark_obs_idx\": tdata_cut_sharks.index,\n",
    "    \"ray_obs_idx\": tdata_cut_rays.index,\n",
    "    \"direction\": [\"exports\", \"imports\"],\n",
    "    \"quantity\": [\"weight\", \"value\"],\n",
    "    \"species\": species_,\n",
    "    \"landing_country\": country_,\n",
    "    \"taxon\": taxon_shortlist,\n",
    "    \"year\":year_,\n",
    "    \"OddsCAT\":np.unique(SppPRIORadj).astype(str)\n",
    "}\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create an empty DataFrame with the specified index and columns\\nscorez = list(np.unique(SppPRIOR).astype(int).astype(str))\\ntradeweightcounts = pd.DataFrame(index=country_, columns=scorez).fillna(0)\\n\\nfor c in country_:\\n    colz, valz = np.unique(SppPRIOR[country_==c,:],return_counts=True)\\n    tradeweightcounts.loc[c,colz.astype(int).astype(str)] = valz\\ntradeweightcounts\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Create an empty DataFrame with the specified index and columns\n",
    "scorez = list(np.unique(SppPRIOR).astype(int).astype(str))\n",
    "tradeweightcounts = pd.DataFrame(index=country_, columns=scorez).fillna(0)\n",
    "\n",
    "for c in country_:\n",
    "    colz, valz = np.unique(SppPRIOR[country_==c,:],return_counts=True)\n",
    "    tradeweightcounts.loc[c,colz.astype(int).astype(str)] = valz\n",
    "tradeweightcounts\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISOex_i</th>\n",
       "      <th>ISOim_j</th>\n",
       "      <th>group</th>\n",
       "      <th>quantity_q</th>\n",
       "      <th>estimated_live_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>rays</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>1.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>rays</td>\n",
       "      <td>788.355375</td>\n",
       "      <td>858.368651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>rays</td>\n",
       "      <td>29.970000</td>\n",
       "      <td>18.836639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ISOex_i ISOim_j group  quantity_q  estimated_live_weight\n",
       "47     CHL     ESP  rays    0.732000               1.171200\n",
       "48     CHL     KOR  rays  788.355375             858.368651\n",
       "49     CHL     PER  rays   29.970000              18.836639"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata_cut_rays[tdata_cut_rays.ISOex_i=='CHL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year_t</th>\n",
       "      <th>exporter_i</th>\n",
       "      <th>importer_j</th>\n",
       "      <th>hscode_k</th>\n",
       "      <th>value_v</th>\n",
       "      <th>quantity_q</th>\n",
       "      <th>hs</th>\n",
       "      <th>product</th>\n",
       "      <th>ISOex_i</th>\n",
       "      <th>ISOim_j</th>\n",
       "      <th>hs_description</th>\n",
       "      <th>fins</th>\n",
       "      <th>rays</th>\n",
       "      <th>group</th>\n",
       "      <th>estimated_live_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111</td>\n",
       "      <td>2012</td>\n",
       "      <td>152</td>\n",
       "      <td>124</td>\n",
       "      <td>30381</td>\n",
       "      <td>102.707</td>\n",
       "      <td>18.013000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>25.205971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>2012</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>8007.364</td>\n",
       "      <td>1912.392000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>2140.840387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>2012</td>\n",
       "      <td>152</td>\n",
       "      <td>604</td>\n",
       "      <td>30381</td>\n",
       "      <td>26.879</td>\n",
       "      <td>24.979000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>34.953642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1370</td>\n",
       "      <td>2013</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>6756.130</td>\n",
       "      <td>1253.065000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>1419.563864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1371</td>\n",
       "      <td>2013</td>\n",
       "      <td>152</td>\n",
       "      <td>458</td>\n",
       "      <td>30381</td>\n",
       "      <td>11.955</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MYS</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>2.124137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1372</td>\n",
       "      <td>2013</td>\n",
       "      <td>152</td>\n",
       "      <td>604</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.063724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1373</td>\n",
       "      <td>2013</td>\n",
       "      <td>152</td>\n",
       "      <td>764</td>\n",
       "      <td>30381</td>\n",
       "      <td>28.583</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>THA</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>4.248275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>2561</td>\n",
       "      <td>2014</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30282</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: fresh or chilled, rays and skates (Rajid...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>2562</td>\n",
       "      <td>2014</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>860.743</td>\n",
       "      <td>139.855000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>223.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>2563</td>\n",
       "      <td>2014</td>\n",
       "      <td>152</td>\n",
       "      <td>604</td>\n",
       "      <td>30281</td>\n",
       "      <td>3.052</td>\n",
       "      <td>2.013000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>Fish: fresh or chilled, dogfish and other shar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>4.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2564</td>\n",
       "      <td>2014</td>\n",
       "      <td>152</td>\n",
       "      <td>764</td>\n",
       "      <td>30381</td>\n",
       "      <td>11.964</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>THA</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>3759</td>\n",
       "      <td>2015</td>\n",
       "      <td>152</td>\n",
       "      <td>124</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>3760</td>\n",
       "      <td>2015</td>\n",
       "      <td>152</td>\n",
       "      <td>344</td>\n",
       "      <td>30381</td>\n",
       "      <td>98.343</td>\n",
       "      <td>63.069000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>HKG</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>126.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>3761</td>\n",
       "      <td>2015</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>410.701</td>\n",
       "      <td>139.303000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>222.884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>3762</td>\n",
       "      <td>2015</td>\n",
       "      <td>152</td>\n",
       "      <td>458</td>\n",
       "      <td>30381</td>\n",
       "      <td>20.088</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MYS</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>3763</td>\n",
       "      <td>2015</td>\n",
       "      <td>152</td>\n",
       "      <td>724</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.098433</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.196865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>3764</td>\n",
       "      <td>2015</td>\n",
       "      <td>152</td>\n",
       "      <td>724</td>\n",
       "      <td>30382</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>1.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>5036</td>\n",
       "      <td>2016</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30282</td>\n",
       "      <td>39.904</td>\n",
       "      <td>6.595000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: fresh or chilled, rays and skates (Rajid...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>10.552000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>5037</td>\n",
       "      <td>2016</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>3644.225</td>\n",
       "      <td>575.433000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>920.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>5038</td>\n",
       "      <td>2016</td>\n",
       "      <td>152</td>\n",
       "      <td>620</td>\n",
       "      <td>30381</td>\n",
       "      <td>56.956</td>\n",
       "      <td>22.146000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>44.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>5039</td>\n",
       "      <td>2016</td>\n",
       "      <td>152</td>\n",
       "      <td>724</td>\n",
       "      <td>30381</td>\n",
       "      <td>63.514</td>\n",
       "      <td>21.584048</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>43.168095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>6338</td>\n",
       "      <td>2017</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>120.786</td>\n",
       "      <td>31.321000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>50.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>7600</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30381</td>\n",
       "      <td>14.632</td>\n",
       "      <td>6.319000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>10.844123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>7601</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>1441.354</td>\n",
       "      <td>265.192000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>364.079732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>7602</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>458</td>\n",
       "      <td>30381</td>\n",
       "      <td>60.801</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MYS</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>11.274868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>7603</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>724</td>\n",
       "      <td>30381</td>\n",
       "      <td>52.719</td>\n",
       "      <td>17.483000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>30.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>8820</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>251</td>\n",
       "      <td>30381</td>\n",
       "      <td>1.787</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.459603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>8821</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>1890.606</td>\n",
       "      <td>357.158000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>224.479688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>8822</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>504</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>HS12</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.037711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12041</th>\n",
       "      <td>12042</td>\n",
       "      <td>2017</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>120.786</td>\n",
       "      <td>33.023000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>52.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13903</th>\n",
       "      <td>13904</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>1264.141</td>\n",
       "      <td>273.922000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>376.065071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>13905</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30497</td>\n",
       "      <td>210.845</td>\n",
       "      <td>42.556000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish meat, excluding fillets, whether or not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>58.424753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>13906</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>458</td>\n",
       "      <td>30381</td>\n",
       "      <td>60.299</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MYS</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>11.274868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>13907</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>724</td>\n",
       "      <td>30381</td>\n",
       "      <td>49.876</td>\n",
       "      <td>17.468000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>29.977077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13907</th>\n",
       "      <td>13908</td>\n",
       "      <td>2018</td>\n",
       "      <td>152</td>\n",
       "      <td>724</td>\n",
       "      <td>30496</td>\n",
       "      <td>5.484</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Fish meat, excluding fillets, whether or not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>1.606283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15668</th>\n",
       "      <td>15669</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>251</td>\n",
       "      <td>30381</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.459603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15669</th>\n",
       "      <td>15670</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>1666.360</td>\n",
       "      <td>368.330000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>231.501474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15670</th>\n",
       "      <td>15671</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30488</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish fillets: frozen, dogfish, other sharks, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.023569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15671</th>\n",
       "      <td>15672</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30497</td>\n",
       "      <td>284.839</td>\n",
       "      <td>57.341000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish meat, excluding fillets, whether or not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>36.039763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15672</th>\n",
       "      <td>15673</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>504</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.037711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15673</th>\n",
       "      <td>15674</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>604</td>\n",
       "      <td>30448</td>\n",
       "      <td>107.428</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>Fish fillets: fresh or chilled, rays and skate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>6.278880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17399</th>\n",
       "      <td>17400</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>251</td>\n",
       "      <td>30381</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.459603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17400</th>\n",
       "      <td>17401</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>1666.360</td>\n",
       "      <td>368.330000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>231.501474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17401</th>\n",
       "      <td>17402</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30488</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish fillets: frozen, dogfish, other sharks, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.023569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17402</th>\n",
       "      <td>17403</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30497</td>\n",
       "      <td>284.839</td>\n",
       "      <td>57.341000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish meat, excluding fillets, whether or not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>36.039763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17403</th>\n",
       "      <td>17404</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>504</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.037711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17404</th>\n",
       "      <td>17405</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>604</td>\n",
       "      <td>30448</td>\n",
       "      <td>107.428</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>Fish fillets: fresh or chilled, rays and skate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>6.278880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19130</th>\n",
       "      <td>19131</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>251</td>\n",
       "      <td>30381</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.459603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19131</th>\n",
       "      <td>19132</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30382</td>\n",
       "      <td>1666.360</td>\n",
       "      <td>368.330000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish: frozen, rays and skates (Rajidae), exclu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>231.501474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19132</th>\n",
       "      <td>19133</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30488</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish fillets: frozen, dogfish, other sharks, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.023569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19133</th>\n",
       "      <td>19134</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>410</td>\n",
       "      <td>30497</td>\n",
       "      <td>284.839</td>\n",
       "      <td>57.341000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Fish meat, excluding fillets, whether or not m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>36.039763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19134</th>\n",
       "      <td>19135</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>504</td>\n",
       "      <td>30381</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Fish: frozen, dogfish and other sharks, exclud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sharks</td>\n",
       "      <td>0.037711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19135</th>\n",
       "      <td>19136</td>\n",
       "      <td>2019</td>\n",
       "      <td>152</td>\n",
       "      <td>604</td>\n",
       "      <td>30448</td>\n",
       "      <td>107.428</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>HS17</td>\n",
       "      <td>meat</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PER</td>\n",
       "      <td>Fish fillets: fresh or chilled, rays and skate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rays</td>\n",
       "      <td>6.278880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  year_t  exporter_i  importer_j  hscode_k   value_v  \\\n",
       "110           111    2012         152         124     30381   102.707   \n",
       "111           112    2012         152         410     30382  8007.364   \n",
       "112           113    2012         152         604     30381    26.879   \n",
       "1369         1370    2013         152         410     30382  6756.130   \n",
       "1370         1371    2013         152         458     30381    11.955   \n",
       "1371         1372    2013         152         604     30381     0.724   \n",
       "1372         1373    2013         152         764     30381    28.583   \n",
       "2560         2561    2014         152         410     30282     0.225   \n",
       "2561         2562    2014         152         410     30382   860.743   \n",
       "2562         2563    2014         152         604     30281     3.052   \n",
       "2563         2564    2014         152         764     30381    11.964   \n",
       "3758         3759    2015         152         124     30381     0.448   \n",
       "3759         3760    2015         152         344     30381    98.343   \n",
       "3760         3761    2015         152         410     30382   410.701   \n",
       "3761         3762    2015         152         458     30381    20.088   \n",
       "3762         3763    2015         152         724     30381     0.053   \n",
       "3763         3764    2015         152         724     30382     0.373   \n",
       "5035         5036    2016         152         410     30282    39.904   \n",
       "5036         5037    2016         152         410     30382  3644.225   \n",
       "5037         5038    2016         152         620     30381    56.956   \n",
       "5038         5039    2016         152         724     30381    63.514   \n",
       "6337         6338    2017         152         410     30382   120.786   \n",
       "7599         7600    2018         152         410     30381    14.632   \n",
       "7600         7601    2018         152         410     30382  1441.354   \n",
       "7601         7602    2018         152         458     30381    60.801   \n",
       "7602         7603    2018         152         724     30381    52.719   \n",
       "8819         8820    2019         152         251     30381     1.787   \n",
       "8820         8821    2019         152         410     30382  1890.606   \n",
       "8821         8822    2019         152         504     30381     0.302   \n",
       "12041       12042    2017         152         410     30382   120.786   \n",
       "13903       13904    2018         152         410     30382  1264.141   \n",
       "13904       13905    2018         152         410     30497   210.845   \n",
       "13905       13906    2018         152         458     30381    60.299   \n",
       "13906       13907    2018         152         724     30381    49.876   \n",
       "13907       13908    2018         152         724     30496     5.484   \n",
       "15668       15669    2019         152         251     30381     1.778   \n",
       "15669       15670    2019         152         410     30382  1666.360   \n",
       "15670       15671    2019         152         410     30488     0.304   \n",
       "15671       15672    2019         152         410     30497   284.839   \n",
       "15672       15673    2019         152         504     30381     0.301   \n",
       "15673       15674    2019         152         604     30448   107.428   \n",
       "17399       17400    2019         152         251     30381     1.778   \n",
       "17400       17401    2019         152         410     30382  1666.360   \n",
       "17401       17402    2019         152         410     30488     0.304   \n",
       "17402       17403    2019         152         410     30497   284.839   \n",
       "17403       17404    2019         152         504     30381     0.301   \n",
       "17404       17405    2019         152         604     30448   107.428   \n",
       "19130       19131    2019         152         251     30381     1.778   \n",
       "19131       19132    2019         152         410     30382  1666.360   \n",
       "19132       19133    2019         152         410     30488     0.304   \n",
       "19133       19134    2019         152         410     30497   284.839   \n",
       "19134       19135    2019         152         504     30381     0.301   \n",
       "19135       19136    2019         152         604     30448   107.428   \n",
       "\n",
       "        quantity_q    hs product ISOex_i ISOim_j  \\\n",
       "110      18.013000  HS12    meat     CHL     CAN   \n",
       "111    1912.392000  HS12    meat     CHL     KOR   \n",
       "112      24.979000  HS12    meat     CHL     PER   \n",
       "1369   1253.065000  HS12    meat     CHL     KOR   \n",
       "1370      1.500000  HS12    meat     CHL     MYS   \n",
       "1371      0.045000  HS12    meat     CHL     PER   \n",
       "1372      3.000000  HS12    meat     CHL     THA   \n",
       "2560      0.015000  HS12    meat     CHL     KOR   \n",
       "2561    139.855000  HS12    meat     CHL     KOR   \n",
       "2562      2.013000  HS12    meat     CHL     PER   \n",
       "2563      1.200000  HS12    meat     CHL     THA   \n",
       "3758      0.066000  HS12    meat     CHL     CAN   \n",
       "3759     63.069000  HS12    meat     CHL     HKG   \n",
       "3760    139.303000  HS12    meat     CHL     KOR   \n",
       "3761      1.950000  HS12    meat     CHL     MYS   \n",
       "3762      0.098433  HS12    meat     CHL     ESP   \n",
       "3763      0.732000  HS12    meat     CHL     ESP   \n",
       "5035      6.595000  HS12    meat     CHL     KOR   \n",
       "5036    575.433000  HS12    meat     CHL     KOR   \n",
       "5037     22.146000  HS12    meat     CHL     PRT   \n",
       "5038     21.584048  HS12    meat     CHL     ESP   \n",
       "6337     31.321000  HS12    meat     CHL     KOR   \n",
       "7599      6.319000  HS12    meat     CHL     KOR   \n",
       "7600    265.192000  HS12    meat     CHL     KOR   \n",
       "7601      6.570000  HS12    meat     CHL     MYS   \n",
       "7602     17.483000  HS12    meat     CHL     ESP   \n",
       "8819      0.585000  HS12    meat     CHL     FRA   \n",
       "8820    357.158000  HS12    meat     CHL     KOR   \n",
       "8821      0.048000  HS12    meat     CHL     MAR   \n",
       "12041    33.023000  HS17    meat     CHL     KOR   \n",
       "13903   273.922000  HS17    meat     CHL     KOR   \n",
       "13904    42.556000  HS17    meat     CHL     KOR   \n",
       "13905     6.570000  HS17    meat     CHL     MYS   \n",
       "13906    17.468000  HS17    meat     CHL     ESP   \n",
       "13907     0.936000  HS17    meat     CHL     ESP   \n",
       "15668     0.585000  HS17    meat     CHL     FRA   \n",
       "15669   368.330000  HS17    meat     CHL     KOR   \n",
       "15670     0.030000  HS17    meat     CHL     KOR   \n",
       "15671    57.341000  HS17    meat     CHL     KOR   \n",
       "15672     0.048000  HS17    meat     CHL     MAR   \n",
       "15673     9.990000  HS17    meat     CHL     PER   \n",
       "17399     0.585000  HS17    meat     CHL     FRA   \n",
       "17400   368.330000  HS17    meat     CHL     KOR   \n",
       "17401     0.030000  HS17    meat     CHL     KOR   \n",
       "17402    57.341000  HS17    meat     CHL     KOR   \n",
       "17403     0.048000  HS17    meat     CHL     MAR   \n",
       "17404     9.990000  HS17    meat     CHL     PER   \n",
       "19130     0.585000  HS17    meat     CHL     FRA   \n",
       "19131   368.330000  HS17    meat     CHL     KOR   \n",
       "19132     0.030000  HS17    meat     CHL     KOR   \n",
       "19133    57.341000  HS17    meat     CHL     KOR   \n",
       "19134     0.048000  HS17    meat     CHL     MAR   \n",
       "19135     9.990000  HS17    meat     CHL     PER   \n",
       "\n",
       "                                          hs_description  fins  rays   group  \\\n",
       "110    Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "111    Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "112    Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "1369   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "1370   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "1371   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "1372   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "2560   Fish: fresh or chilled, rays and skates (Rajid...     0     1    rays   \n",
       "2561   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "2562   Fish: fresh or chilled, dogfish and other shar...     0     0  sharks   \n",
       "2563   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "3758   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "3759   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "3760   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "3761   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "3762   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "3763   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "5035   Fish: fresh or chilled, rays and skates (Rajid...     0     1    rays   \n",
       "5036   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "5037   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "5038   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "6337   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "7599   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "7600   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "7601   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "7602   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "8819   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "8820   Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "8821   Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "12041  Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "13903  Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "13904  Fish meat, excluding fillets, whether or not m...     0     1    rays   \n",
       "13905  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "13906  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "13907  Fish meat, excluding fillets, whether or not m...     0     0  sharks   \n",
       "15668  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "15669  Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "15670  Fish fillets: frozen, dogfish, other sharks, r...     0     0  sharks   \n",
       "15671  Fish meat, excluding fillets, whether or not m...     0     1    rays   \n",
       "15672  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "15673  Fish fillets: fresh or chilled, rays and skate...     0     1    rays   \n",
       "17399  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "17400  Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "17401  Fish fillets: frozen, dogfish, other sharks, r...     0     0  sharks   \n",
       "17402  Fish meat, excluding fillets, whether or not m...     0     1    rays   \n",
       "17403  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "17404  Fish fillets: fresh or chilled, rays and skate...     0     1    rays   \n",
       "19130  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "19131  Fish: frozen, rays and skates (Rajidae), exclu...     0     1    rays   \n",
       "19132  Fish fillets: frozen, dogfish, other sharks, r...     0     0  sharks   \n",
       "19133  Fish meat, excluding fillets, whether or not m...     0     1    rays   \n",
       "19134  Fish: frozen, dogfish and other sharks, exclud...     0     0  sharks   \n",
       "19135  Fish fillets: fresh or chilled, rays and skate...     0     1    rays   \n",
       "\n",
       "       estimated_live_weight  \n",
       "110                25.205971  \n",
       "111              2140.840387  \n",
       "112                34.953642  \n",
       "1369             1419.563864  \n",
       "1370                2.124137  \n",
       "1371                0.063724  \n",
       "1372                4.248275  \n",
       "2560                0.024000  \n",
       "2561              223.768000  \n",
       "2562                4.026000  \n",
       "2563                2.400000  \n",
       "3758                0.132000  \n",
       "3759              126.138000  \n",
       "3760              222.884800  \n",
       "3761                3.900000  \n",
       "3762                0.196865  \n",
       "3763                1.171200  \n",
       "5035               10.552000  \n",
       "5036              920.692800  \n",
       "5037               44.292000  \n",
       "5038               43.168095  \n",
       "6337               50.113600  \n",
       "7599               10.844123  \n",
       "7600              364.079732  \n",
       "7601               11.274868  \n",
       "7602               30.002819  \n",
       "8819                0.459603  \n",
       "8820              224.479688  \n",
       "8821                0.037711  \n",
       "12041              52.836800  \n",
       "13903             376.065071  \n",
       "13904              58.424753  \n",
       "13905              11.274868  \n",
       "13906              29.977077  \n",
       "13907               1.606283  \n",
       "15668               0.459603  \n",
       "15669             231.501474  \n",
       "15670               0.023569  \n",
       "15671              36.039763  \n",
       "15672               0.037711  \n",
       "15673               6.278880  \n",
       "17399               0.459603  \n",
       "17400             231.501474  \n",
       "17401               0.023569  \n",
       "17402              36.039763  \n",
       "17403               0.037711  \n",
       "17404               6.278880  \n",
       "19130               0.459603  \n",
       "19131             231.501474  \n",
       "19132               0.023569  \n",
       "19133              36.039763  \n",
       "19134               0.037711  \n",
       "19135               6.278880  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata[tdata.ISOex_i=='CHL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
