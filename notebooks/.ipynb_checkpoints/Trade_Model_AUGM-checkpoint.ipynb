{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for shark and ray meat trade\n",
    "\n",
    "This code implements a probabalistic model to estimate the proportions of species traded among major shark fishing and trading nations. A previous model uses expert opinion as prior information to estimate the total latent landings in any given country and this model allocates these landings to potential trading partners based on trade friction and importer preferences. Model developmenet has been primarily from Aaron MacNeil, Beth Babcock, Chris Mull, and Alex Andorra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pyt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import xarray as xr\n",
    "import xarray_einstats\n",
    "import rdata as rd\n",
    "import mcbackend\n",
    "import clickhouse_driver\n",
    "import networkx as nx\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure style.\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "# point to data and figure directories\n",
    "bd = os.getcwd() + \"/../Data/\"\n",
    "bf = os.getcwd() + \"/../Figures/\"\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def indexall(L):\n",
    "    poo = []\n",
    "    for p in L:\n",
    "        if not p in poo:\n",
    "            poo.append(p)\n",
    "    Ix = np.array([poo.index(p) for p in L])\n",
    "    return poo, Ix\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "match = lambda a, b: np.array([b.index(x) if x in b else None for x in a])\n",
    "\n",
    "def zscore(x):\n",
    "    return (x-np.mean(x))/np.std(x)\n",
    "\n",
    "def unique(series: pd.Series):\n",
    "    \"Helper function to sort and isolate unique values of a Pandas Series\"\n",
    "    return series.sort_values().unique()\n",
    "\n",
    "\n",
    "# Script to generate interpolated PyMC distribution objects\n",
    "def from_posterior(param, samples):\n",
    "    smin, smax = samples.min().item(), samples.max().item()\n",
    "    width = smax - smin\n",
    "    x = np.linspace(smin, smax, 100)\n",
    "    y = sp.stats.gaussian_kde(samples)(x)\n",
    "\n",
    "    # what was never sampled should have a small probability but not 0,\n",
    "    # so we'll extend the domain and use linear approximation of density on it\n",
    "    x = np.concatenate([[x[0] - 3 * width], x, [x[-1] + 3 * width]])\n",
    "    y = np.concatenate([[0], y, [0]])\n",
    "    return pm.Interpolated(param, x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "exec(open(\"Joint_Trade_Landings_Data_AUGM.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize backend\n",
    "#ch_client = clickhouse_driver.Client(host=\"xxx.xxx.xxx.xxx\", password='your-pwd', database='gsmtdb')\n",
    "# Backend object\n",
    "#ch_backend = mcbackend.ClickHouseBackend(ch_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List backend runs available\n",
    "#rxid = ch_backend.get_runs()\n",
    "#rxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the run from the database (downloads just metadata from most recent run)\n",
    "#model_run = ch_backend.get_run('XXXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MultiTrace objects from server\n",
    "#IDATA = model_run.to_inferencedata(var_names=['latent_logOdds_landings_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import landings log-odds posteriors\n",
    "IDATA = az.from_netcdf(\"idata-landings-model_AUGM.nc\")\n",
    "\n",
    "latent_logOdds_landings_mu = IDATA.posterior['latent_logOdds_landings_'].mean(('chain','draw')).to_numpy()\n",
    "latent_logOdds_landings_sd = IDATA.posterior['latent_logOdds_landings_'].std(('chain','draw')).to_numpy()\n",
    "\n",
    "# Remove IDATA object\n",
    "IDATA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for dyads\n",
    "dyad_mask = (trade_mask.max(1)!=-999)*1\n",
    "# Mask for importer species prefs\n",
    "ispp_mask = (trade_mask.max(0)!=-999)*1\n",
    "# Log-seafood trade and mask\n",
    "total_seafood_trade[total_seafood_trade<=1] = 0\n",
    "log_total_seafood_trade = np.log1p(total_seafood_trade.to_numpy())\n",
    "lst_mask = (log_total_seafood_trade>0)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Joint landings trade model - sharks and rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronmacneil/miniforge3/envs/gsm-project/lib/python3.11/site-packages/pymc/data.py:433: UserWarning: The `mutable` kwarg was not specified. Before v4.1.0 it defaulted to `pm.Data(mutable=True)`, which is equivalent to using `pm.MutableData()`. In v4.1.0 the default changed to `pm.Data(mutable=False)`, equivalent to `pm.ConstantData`. Use `pm.ConstantData`/`pm.MutableData` or pass `pm.Data(..., mutable=False/True)` to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with pm.Model(coords=COORDS) as trade_model_x:\n",
    "    # --------------------------------------------------------\n",
    "    #                     Data containers\n",
    "    # --------------------------------------------------------\n",
    "    \n",
    "    shark_exporter_id = pm.Data(\n",
    "        \"shark_exporter_id\", shark_exporter_idx, dims=\"shark_obs_idx\"\n",
    "    )\n",
    "    shark_importer_id = pm.Data(\n",
    "        \"shark_importer_id\", shark_importer_idx, dims=\"shark_obs_idx\"\n",
    "    )\n",
    "    ray_exporter_id = pm.Data(\n",
    "        \"ray_exporter_id\", ray_exporter_idx, dims=\"ray_obs_idx\"\n",
    "    )\n",
    "    ray_importer_id = pm.Data(\n",
    "        \"ray_importer_id\", ray_importer_idx, dims=\"ray_obs_idx\"\n",
    "    )\n",
    "    unreliability_data = pm.Data(\n",
    "        \"unreliability_data\", unreliability_score[\"exporter\"], dims=\"exporter\"\n",
    "    )\n",
    "    log_seafood_trade = pm.Data(\n",
    "        \"log_seafood_trade\",\n",
    "        np.log(total_seafood_trade+0.0001),\n",
    "        dims=(\"exporter\", \"importer\"),\n",
    "    )\n",
    "    z_seafood_trade = pm.Data(\n",
    "        \"z_seafood_trade\",\n",
    "        zscore(np.log(total_seafood_trade.to_numpy()+0.0001)),\n",
    "        dims=(\"exporter\", \"importer\"),\n",
    "    )\n",
    "    log_shark_trade_data = pm.Data(\n",
    "        \"log_shark_trade_data\",\n",
    "        np.log(tdata_cut_sharks[\"estimated_live_weight\"]),\n",
    "        dims=\"shark_obs_idx\",\n",
    "    )\n",
    "    shark_trade_data = pm.Data(\n",
    "        \"shark_trade_data\",\n",
    "        tdata_cut_sharks[\"estimated_live_weight\"],\n",
    "        dims=\"shark_obs_idx\",\n",
    "    )\n",
    "    log_ray_trade_data = pm.Data(\n",
    "        \"log_ray_trade_data\",\n",
    "        np.log(tdata_cut_rays[\"estimated_live_weight\"]),\n",
    "        dims=\"ray_obs_idx\",\n",
    "    )\n",
    "    ray_trade_data = pm.Data(\n",
    "        \"ray_trade_data\",\n",
    "        tdata_cut_rays[\"estimated_live_weight\"],\n",
    "        dims=\"ray_obs_idx\",\n",
    "    )\n",
    "    TradeWeights = pm.Data(\n",
    "        \"TradeWeights\",\n",
    "        tradeweights.to_numpy(),\n",
    "        dims=(\"exporter\", \"species\", \"importer\"),\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    #                   Landings model\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    #\"\"\"\n",
    "    # Set index cutoff - removes impossible -999 species from likelihood\n",
    "    isppx = SppPRIORadj > -5\n",
    "\n",
    "\n",
    "    # National average log odds for latent landings by species\n",
    "    latent_logOdds_landings_ = pm.Normal(\"latent_logOdds_landings_\", latent_logOdds_landings_mu, latent_logOdds_landings_sd+0.1)\n",
    "\n",
    "    latent_logOdds_landings = pm.Deterministic(\n",
    "        \"latent_logOdds_landings\",\n",
    "        pyt.set_subtensor((pyt.ones(SppPRIOR.shape)*-9)[isppx], latent_logOdds_landings_),\n",
    "        dims=(\"exporter\", \"species\")\n",
    "    )\n",
    "\n",
    "    # Species proportions of total landings\n",
    "    SppProps = pm.Deterministic(\n",
    "        \"SppProps\",\n",
    "        pm.math.softmax(latent_logOdds_landings,axis=1),\n",
    "        dims=(\"exporter\", \"species\")\n",
    "    )\n",
    "    \n",
    "    # National average landings\n",
    "    Latent_landings = pm.Deterministic(\n",
    "        \"Latent_landings\",\n",
    "        SppProps*TotalCatch[:,None],\n",
    "        dims=(\"exporter\", \"species\")\n",
    "    )\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    #           TRADE MODEL\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    intercept = pm.Normal(\"intercept\", 0, 3)\n",
    "    \n",
    "    #importer_species_effect = pm.Normal(\"importer_species_effect\", 0, 3, dims=(\"species\", \"importer\"))\n",
    "    importer_species_effect = pm.ZeroSumNormal(\"importer_species_effect\", 3, dims=(\"species\", \"importer\"), n_zerosum_axes=2)\n",
    "    \n",
    "    #dyad_effect = pm.Normal(\"dyad_effect\", 0, 3, dims=(\"exporter\", \"importer\"))\n",
    "    dyad_effect = pm.ZeroSumNormal(\"dyad_effect\", 3, dims=(\"exporter\", \"importer\"), n_zerosum_axes=2)\n",
    "    \n",
    "    # trade affinity between countries\n",
    "    trade_effect = pm.Normal(\"trade_effect\", 0, 3)\n",
    "    \n",
    "    # exporters' propensity to sell species\n",
    "    # doesn't have to sum to 1 across species\n",
    "    # has to sum to 1 across importers\n",
    "    export_proportion = pm.Deterministic(\n",
    "        \"export_proportion\", \n",
    "        pm.math.softmax(\n",
    "            (intercept\n",
    "            + importer_species_effect[None, :, :]\n",
    "            + dyad_effect[:, None, :]\n",
    "            + (trade_effect * z_seafood_trade)[:, None, :]\n",
    "            + trade_mask\n",
    "            + TradeWeights\n",
    "            )\n",
    "            , axis=2\n",
    "        ),\n",
    "        dims=(\"exporter\", \"species\", \"importer\")\n",
    "    )\n",
    "    \n",
    "    # Amount exported\n",
    "    amount_exported = pm.Deterministic(\n",
    "        \"amount_exported\",\n",
    "        ((export_proportion)*(Latent_landings[:, :, None])),\n",
    "        dims=(\"exporter\", \"species\", \"importer\"),\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    #                    Sum across species\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    expected_log_shark_trade = pm.Deterministic(\n",
    "        \"expected_log_shark_trade\",\n",
    "        pyt.log((amount_exported*shark_mask[None,:,None]).sum(1)+0.0001),\n",
    "        dims=(\"exporter\", \"importer\"),\n",
    "    )\n",
    "    expected_log_ray_trade = pm.Deterministic(\n",
    "        \"expected_log_ray_trade\",\n",
    "        pyt.log((amount_exported*ray_mask[None,:,None]).sum(1)+0.0001),\n",
    "        dims=(\"exporter\", \"importer\"),\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    #       Modeling exporters' reporting unreliability\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    lsd_intercept_sd = pm.Exponential(\"lsd_intercept_sd\", 1)\n",
    "    lsd_intercept = pm.Normal(\"lsd_intercept\", sigma=lsd_intercept_sd)\n",
    "\n",
    "    lsd_unreliability_sd = pm.Exponential(\"lsd_unreliability_sd\", 1)\n",
    "    lsd_unreliability_effect = pm.Normal(\n",
    "        #\"lsd_unreliability_effect\", sigma=lsd_unreliability_sd, dims=\"exporter\"\n",
    "        \"lsd_unreliability_effect\", sigma=lsd_unreliability_sd, dims=\"exporter\"\n",
    "    )\n",
    "\n",
    "    reliability = pyt.exp(\n",
    "        lsd_intercept + lsd_unreliability_effect * unreliability_data\n",
    "    )\n",
    "    #\"\"\"\n",
    "    # --------------------------------------------------------\n",
    "    #                    Likelihood of trade\n",
    "    # --------------------------------------------------------\n",
    "    #\"\"\"\n",
    "    pm.Normal(\n",
    "        \"log_shark_trade\",\n",
    "        mu=expected_log_shark_trade[shark_exporter_id, shark_importer_id],\n",
    "        sigma=reliability[shark_exporter_id],\n",
    "        observed=log_shark_trade_data,\n",
    "        dims=\"shark_obs_idx\",\n",
    "    )\n",
    "    \n",
    "    pm.Normal(\n",
    "        \"log_ray_trade\",\n",
    "        mu=expected_log_ray_trade[ray_exporter_id, ray_importer_id],\n",
    "        sigma=reliability[ray_exporter_id],\n",
    "        observed=log_ray_trade_data,\n",
    "        dims=\"ray_obs_idx\",\n",
    "    )\n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [latent_logOdds_landings_, intercept, importer_species_effect, dyad_effect, trade_effect, lsd_intercept_sd, lsd_intercept, lsd_unreliability_sd, lsd_unreliability_effect]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='800' class='' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [800/800 1:45:16&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 100 tune and 100 draw iterations (400 + 400 draws total) took 6317 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done sampling\n"
     ]
    }
   ],
   "source": [
    "with trade_model_x:\n",
    "    #trade_model_x = pm.sample(draws=500, tune=1000, trace=ch_backend, idata_kwargs=dict(log_likelihood=False))\n",
    "    idata_trade_x = pm.sample(draws=100, tune=100, idata_kwargs=dict(log_likelihood=False))\n",
    "print('Done sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [dyad_effect, importer_species_effect, intercept, latent_logOdds_landings_, log_ray_trade, log_shark_trade, lsd_intercept, lsd_intercept_sd, lsd_unreliability_effect, lsd_unreliability_sd, trade_effect]\n",
      "Sampling: [log_ray_trade, log_shark_trade]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='400' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [400/400 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done predictives\n"
     ]
    }
   ],
   "source": [
    "# Sample from prior and posterior predictive distributions\n",
    "#\"\"\"\n",
    "with trade_model_x:\n",
    "    try:\n",
    "        idata_trade_x.extend(pm.sample_prior_predictive())\n",
    "        idata_trade_x.extend(pm.sample_posterior_predictive(idata_trade_x))\n",
    "        print('Done predictives')\n",
    "    except:\n",
    "        print('Failed predictives')\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trace!\n"
     ]
    }
   ],
   "source": [
    "# Export results\n",
    "idata_trade_x.to_netcdf(\"idata-trade-model_AUGM.nc\")\n",
    "print(\"Saved trace!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
